"""
æ•°æ®åº“ç®¡ç†å™¨ï¼Œè´Ÿè´£å¤„ç†ä¹¦ç±å…ƒæ•°æ®çš„æ•°æ®åº“å­˜å‚¨
"""

import os
import sqlite3
import requests
import socket

import json
import time
from typing import Dict, List, Optional, Any
from pathlib import Path
from datetime import datetime

from src.core.book import Book
from src.config.config_manager import ConfigManager
from src.utils.logger import get_logger

logger = get_logger(__name__)

# æ‹¼éŸ³è½¬æ¢å·¥å…·
try:
    from pypinyin import pinyin, Style  # type: ignore[reportMissingImports]
    _PY_PINYIN_AVAILABLE = True
except Exception:
    _PY_PINYIN_AVAILABLE = False
    pinyin = None  # type: ignore[assignment]
    Style = None   # type: ignore[assignment]
    logger.warning("pypinyinåº“æœªå®‰è£…ï¼Œæ‹¼éŸ³åŠŸèƒ½å°†ä¸å¯ç”¨")

def convert_to_pinyin(text: str) -> str:
    """
    å°†ä¸­æ–‡è½¬æ¢ä¸ºæ‹¼éŸ³
    
    Args:
        text: ä¸­æ–‡å­—ç¬¦ä¸²
        
    Returns:
        str: æ‹¼éŸ³å­—ç¬¦ä¸²
    """
    if not _PY_PINYIN_AVAILABLE:
        return ""
    
    try:
        # ä½¿ç”¨æ™®é€šé£æ ¼ï¼Œä¸å¸¦å£°è°ƒ
        pinyin_list = pinyin(text, style=Style.NORMAL)  # type: ignore
        return "".join([item[0] for item in pinyin_list if item])
    except Exception as e:
        logger.error(f"æ‹¼éŸ³è½¬æ¢å¤±è´¥: {e}")
        return ""

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨ç±»"""
    
    def __init__(self, db_path: Optional[str] = None):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„
        """
        if db_path is None:
            config = ConfigManager.get_instance().get_config()
            self.db_path = os.path.expanduser(config["paths"]["database"])
        else:
            # å¦‚æœä¼ å…¥çš„æ˜¯ç›®å½•è·¯å¾„ï¼Œåˆ™æ‹¼æ¥å®Œæ•´çš„æ•°æ®åº“æ–‡ä»¶è·¯å¾„
            if os.path.isdir(db_path):
                self.db_path = os.path.join(db_path, "database.sqlite")
            else:
                self.db_path = os.path.expanduser(db_path)
            
        # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨ï¼ˆå¦‚æœæ˜¯å†…å­˜æ•°æ®åº“åˆ™è·³è¿‡ï¼‰
        if self.db_path != ':memory:':
            os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        self._init_database()
    
    def get_db_path(self) -> str:
        """
        è·å–æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        
        Returns:
            str: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        return self.db_path
    
    def _add_column_if_not_exists(self, cursor: sqlite3.Cursor, table_name: str, column_name: str, 
                                  column_type: str, default_value: str = "") -> None:
        """
        å¦‚æœåˆ—ä¸å­˜åœ¨åˆ™æ·»åŠ åˆ—
        
        Args:
            cursor: æ•°æ®åº“æ¸¸æ ‡
            table_name: è¡¨å
            column_name: åˆ—å
            column_type: åˆ—ç±»å‹
            default_value: é»˜è®¤å€¼
        """
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = [column[1] for column in cursor.fetchall()]
        if column_name not in columns:
            alter_sql = f"ALTER TABLE {table_name} ADD COLUMN {column_name} {column_type}"
            if default_value:
                alter_sql += f" DEFAULT {default_value}"
            cursor.execute(alter_sql)
            logger.info(f"å·²ä¸º{table_name}è¡¨æ·»åŠ {column_name}åˆ—")
    
    def _init_database(self) -> None:
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # å¯ç”¨ WAL æ¨¡å¼ä»¥æ”¯æŒå¹¶å‘è¯»å†™
            # WAL æ¨¡å¼å…è®¸å¤šä¸ªè¯»æ“ä½œå’Œä¸€ä¸ªå†™æ“ä½œåŒæ—¶è¿›è¡Œ
            cursor.execute("PRAGMA journal_mode = WAL")
            logger.info("æ•°æ®åº“ WAL æ¨¡å¼å·²å¯ç”¨ï¼Œæ”¯æŒå¹¶å‘è¯»å†™")
            
            # è®¾ç½®ç¹å¿™è¶…æ—¶ï¼ˆ5ç§’ï¼‰ï¼Œå½“æ•°æ®åº“è¢«é”å®šæ—¶ç­‰å¾…æœ€å¤š5ç§’
            cursor.execute("PRAGMA busy_timeout = 5000")
            logger.info("æ•°æ®åº“ç¹å¿™è¶…æ—¶å·²è®¾ç½®ä¸º 5000ms")
            
            # æ ¹æ®é…ç½®å¯ç”¨auto_vacuumä»¥é¿å…æ•°æ®åº“è‡ƒè‚¿
            config = ConfigManager.get_instance().get_config()
            auto_vacuum_enabled = config.get("advanced", {}).get("auto_vacuum_enabled", True)
            if auto_vacuum_enabled:
                cursor.execute("PRAGMA auto_vacuum = 1")
                logger.info("æ•°æ®åº“è‡ªåŠ¨æ¸…ç†å·²å¯ç”¨")
            else:
                cursor.execute("PRAGMA auto_vacuum = 0")
                logger.info("æ•°æ®åº“è‡ªåŠ¨æ¸…ç†å·²ç¦ç”¨")
            
            # åˆ›å»ºä¹¦ç±è¡¨ï¼ˆåˆ é™¤last_read_dateã€reading_progressã€total_pagesã€word_countå­—æ®µï¼‰
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS books (
                    path TEXT PRIMARY KEY,
                    title TEXT NOT NULL,
                    pinyin TEXT,
                    author TEXT NOT NULL,
                    format TEXT NOT NULL,
                    add_date TEXT NOT NULL,
                    tags TEXT,
                    metadata TEXT,
                    file_size INTEGER DEFAULT 0  -- æ–°å¢æ–‡ä»¶å¤§å°å­—æ®µï¼Œå•ä½ä¸ºå­—èŠ‚
                )
            """)
            
            # ä¼ªç”¨æˆ·ç³»ç»Ÿï¼šç”¨æˆ·ã€æƒé™ã€å½’å±è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS users (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username TEXT NOT NULL UNIQUE,
                    password_hash TEXT NOT NULL,
                    role TEXT NOT NULL DEFAULT 'user',
                    created_at TEXT NOT NULL
                )
            """)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS permissions (
                    key TEXT PRIMARY KEY,
                    description TEXT DEFAULT ''
                )
            """)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS user_permissions (
                    user_id INTEGER NOT NULL,
                    perm_key TEXT NOT NULL,
                    allowed INTEGER NOT NULL DEFAULT 1,
                    PRIMARY KEY (user_id, perm_key),
                    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE,
                    FOREIGN KEY (perm_key) REFERENCES permissions (key) ON DELETE CASCADE
                )
            """)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS user_books (
                    user_id INTEGER NOT NULL,
                    book_path TEXT NOT NULL,
                    PRIMARY KEY (user_id, book_path),
                    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE,
                    FOREIGN KEY (book_path) REFERENCES books (path) ON DELETE CASCADE
                )
            """)
            # å®Œæ•´æƒé™é¢„ç½®ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™æ’å…¥ï¼‰- åŒ…å«æ‰€æœ‰é¡µé¢çš„æŒ‰é’®æƒé™
            default_perms = [
                # æ¬¢è¿å±å¹•æƒé™
                ('welcome.open_book', 'æ¬¢è¿å±å¹•.æ‰“å¼€ä¹¦ç±'),
                ('welcome.browse_library', 'æ¬¢è¿å±å¹•.æµè§ˆä¹¦åº“'),
                ('welcome.get_books', 'æ¬¢è¿å±å¹•.è·å–ä¹¦ç±'),
                ('welcome.settings', 'æ¬¢è¿å±å¹•.æ‰“å¼€è®¾ç½®'),
                ('welcome.statistics', 'æ¬¢è¿å±å¹•.æ‰“å¼€ç»Ÿè®¡'),
                ('welcome.help', 'æ¬¢è¿å±å¹•.æ‰“å¼€å¸®åŠ©'),
                ('welcome.manage', 'æ¬¢è¿å±å¹•.ç®¡ç†ç”¨æˆ·'),
                ('welcome.exit', 'æ¬¢è¿å±å¹•.é€€å‡ºåº”ç”¨'),
                
                # ä¹¦æ¶æƒé™
                ('bookshelf.read', 'ä¹¦åº“.é˜…è¯»ä¹¦ç±'),
                ('bookshelf.view_file', 'ä¹¦åº“.æŸ¥çœ‹ä¹¦ç±æ–‡ä»¶'),
                ('bookshelf.delete_book', 'ä¹¦åº“.åˆ é™¤ä¹¦ç±'),
                ('bookshelf.add_book', 'ä¹¦åº“.æ·»åŠ ä¹¦ç±'),
                ('bookshelf.scan_directory', 'ä¹¦åº“.æ‰«æç›®å½•æ·»åŠ ä¹¦ç±'),
                ('bookshelf.get_books', 'ä¹¦åº“.è·å–ä¹¦ç±é¡µé¢'),
                ('bookshelf.search', 'ä¹¦åº“.æœç´¢ä¹¦ç±'),
                ('bookshelf.sort', 'ä¹¦åº“.æ’åºä¹¦ç±'),
                ('bookshelf.batch_ops', 'ä¹¦åº“.æ‰¹é‡æ“ä½œä¹¦ç±'),
                ('bookshelf.refresh', 'ä¹¦åº“.åˆ·æ–°ä¹¦æ¶'),
                
                # æ–‡ä»¶èµ„æºç®¡ç†å™¨æƒé™
                ('file_explorer.back', 'æ–‡ä»¶èµ„æºç®¡ç†å™¨.è¿”å›ä¸Šçº§ç›®å½•'),
                ('file_explorer.go', 'æ–‡ä»¶èµ„æºç®¡ç†å™¨.å¯¼èˆªåˆ°è·¯å¾„'),
                ('file_explorer.home', 'æ–‡ä»¶èµ„æºç®¡ç†å™¨.è¿”å›ä¸»ç›®å½•'),
                ('file_explorer.select', 'æ–‡ä»¶èµ„æºç®¡ç†å™¨.é€‰æ‹©æ–‡ä»¶/ç›®å½•'),
                ('file_explorer.cancel', 'æ–‡ä»¶èµ„æºç®¡ç†å™¨.å–æ¶ˆæ“ä½œ'),
                
                # ç›®å½•å¯¹è¯æ¡†æƒé™
                ('directory_dialog.select', 'ç›®å½•å¯¹è¯æ¡†.é€‰æ‹©ç›®å½•'),
                ('directory_dialog.cancel', 'ç›®å½•å¯¹è¯æ¡†.å–æ¶ˆæ“ä½œ'),
                
                # æ–‡ä»¶é€‰æ‹©å™¨å¯¹è¯æ¡†æƒé™
                ('file_chooser.select', 'æ–‡ä»¶é€‰æ‹©å™¨å¯¹è¯æ¡†.é€‰æ‹©æ–‡ä»¶'),
                ('file_chooser.cancel', 'æ–‡ä»¶é€‰æ‹©å™¨å¯¹è¯æ¡†.å–æ¶ˆæ“ä½œ'),
                ('file_chooser.add_file', 'æ–‡ä»¶é€‰æ‹©å™¨å¯¹è¯æ¡†.æ·»åŠ æ–‡ä»¶'),
                
                # è·å–ä¹¦ç±æƒé™
                ('get_books.novel_sites', 'è·å–ä¹¦ç±é¡µé¢.å°è¯´ç½‘ç«™ç®¡ç†'),
                ('get_books.proxy_settings', 'è·å–ä¹¦ç±é¡µé¢.ä»£ç†è®¾ç½®'),
                ('get_books.back', 'è·å–ä¹¦ç±é¡µé¢.ç¦»å¼€è·å–ä¹¦ç±'),
                
                # è®¾ç½®æƒé™
                ('settings.save', 'è®¾ç½®ä¸­å¿ƒ.ä¿å­˜è®¾ç½®'),
                ('settings.cancel', 'è®¾ç½®ä¸­å¿ƒ.å–æ¶ˆè®¾ç½®'),
                ('settings.reset', 'è®¾ç½®ä¸­å¿ƒ.é‡ç½®è®¾ç½®'),
                ('settings.open', 'è®¾ç½®ä¸­å¿ƒ.æ‰“å¼€è®¾ç½®'),
                
                # ç»Ÿè®¡æƒé™
                ('statistics.refresh', 'ç»Ÿè®¡é¡µé¢.åˆ·æ–°ç»Ÿè®¡'),
                ('statistics.export', 'ç»Ÿè®¡é¡µé¢.å¯¼å‡ºç»Ÿè®¡'),
                ('statistics.reset', 'ç»Ÿè®¡é¡µé¢.é‡ç½®ç»Ÿè®¡'),
                ('statistics.back', 'ç»Ÿè®¡é¡µé¢.ç¦»å¼€ç»Ÿè®¡'),
                ('statistics.open', 'ç»Ÿè®¡é¡µé¢.æ‰“å¼€ç»Ÿè®¡'),
                
                # ç”¨æˆ·ç®¡ç†æƒé™
                ('users.add_user', 'ç”¨æˆ·ç®¡ç†.æ·»åŠ ç”¨æˆ·'),
                ('users.edit_user', 'ç”¨æˆ·ç®¡ç†.ç¼–è¾‘ç”¨æˆ·'),
                ('users.delete_user', 'ç”¨æˆ·ç®¡ç†.åˆ é™¤ç”¨æˆ·'),
                ('users.set_permissions', 'ç”¨æˆ·ç®¡ç†.è®¾ç½®æƒé™'),
                ('users.view_permissions', 'ç”¨æˆ·ç®¡ç†.æŸ¥çœ‹æƒé™'),
                ('users.back', 'ç”¨æˆ·ç®¡ç†.ç¦»å¼€ç®¡ç†ç”¨æˆ·ä¸æƒé™'),
                ('admin.manage_users', 'ç”¨æˆ·ç®¡ç†.ç®¡ç†ç”¨æˆ·ä¸æƒé™'),
                                
                # çˆ¬è™«æƒé™
                ('crawler.open', 'æ‰“å¼€çˆ¬å–ç®¡ç†é¡µé¢'),
                ('crawler.run', 'æ‰§è¡Œçˆ¬å–ä»»åŠ¡'),
                
                # ä¹¦ç­¾æƒé™
                ('bookmarks.add', 'ä¹¦ç­¾.æ·»åŠ ä¹¦ç­¾'),
                ('bookmarks.edit', 'ä¹¦ç­¾.ç¼–è¾‘ä¹¦ç­¾'),
                ('bookmarks.delete', 'ä¹¦ç­¾.åˆ é™¤ä¹¦ç­¾'),
                ('bookmarks.view', 'ä¹¦ç­¾.æŸ¥çœ‹ä¹¦ç­¾'),
                
                # å¸®åŠ©æƒé™
                ('help.open', 'æ‰“å¼€å¸®åŠ©ä¸­å¿ƒ'),
                ('help.back', 'ç¦»å¼€å¸®åŠ©ä¸­å¿ƒ'),
                
                # è€æ¿é”®æƒé™
                ('boss_key.activate', 'æ¿€æ´»è€æ¿é”®'),
                ('boss_key.deactivate', 'å–æ¶ˆè€æ¿é”®')
            ]
            for k, d in default_perms:
                cursor.execute("INSERT OR IGNORE INTO permissions (key, description) VALUES (?, ?)", (k, d))
            # é»˜è®¤è¶…çº§ç®¡ç†å‘˜è´¦å·ï¼šadmin/admin
            try:
                cursor.execute("SELECT id FROM users WHERE username = ?", ("admin",))
                row = cursor.fetchone()
                if not row:
                    cursor.execute(
                        "INSERT INTO users (username, password_hash, role, created_at) VALUES (?, ?, ?, ?)",
                        ("admin", self._hash_password("admin"), "superadmin", datetime.now().isoformat())
                    )
                    # è·å–æ–°åˆ›å»ºçš„adminç”¨æˆ·ID
                    cursor.execute("SELECT id FROM users WHERE username = ?", ("admin",))
                    admin_row = cursor.fetchone()
                    if admin_row:
                        admin_id = admin_row[0]
                        # ä¸ºadminç”¨æˆ·åˆ†é…æ–‡ä»¶èµ„æºç®¡ç†å™¨ç›¸å…³æƒé™
                        file_explorer_perms = [
                            'file_explorer.back', 'file_explorer.go', 'file_explorer.home',
                            'file_explorer.select', 'file_explorer.cancel'
                        ]
                        for perm in file_explorer_perms:
                            cursor.execute(
                                "INSERT OR REPLACE INTO user_permissions (user_id, perm_key, allowed) VALUES (?, ?, 1)",
                                (admin_id, perm)
                            )
                        
                        # ä¸ºadminç”¨æˆ·åˆ†é…å¯¹è¯æ¡†ç›¸å…³æƒé™
                        dialog_perms = [
                            'directory_dialog.select', 'directory_dialog.cancel',
                            'file_chooser.select', 'file_chooser.cancel', 'file_chooser.add_file'
                        ]
                        for perm in dialog_perms:
                            cursor.execute(
                                "INSERT OR REPLACE INTO user_permissions (user_id, perm_key, allowed) VALUES (?, ?, 1)",
                                (admin_id, perm)
                            )
            except Exception as _e:
                logger.warning(f"åˆ›å»ºé»˜è®¤è¶…çº§ç®¡ç†å‘˜å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰ï¼š{_e}")
            
            # åˆ›å»ºé˜…è¯»å†å²è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS reading_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    book_path TEXT NOT NULL,
                    read_date TEXT NOT NULL,
                    duration INTEGER NOT NULL,
                    pages_read INTEGER DEFAULT 0,
                    user_id INTEGER DEFAULT 0,
                    reading_progress REAL DEFAULT 0,
                    total_pages INTEGER DEFAULT 0,
                    word_count INTEGER DEFAULT 0,
                    metadata TEXT,
                    FOREIGN KEY (book_path) REFERENCES books (path) ON DELETE CASCADE
                )
            """)
            
            # åˆ›å»ºä¹¦ç±å…ƒæ•°æ®è¡¨ï¼ˆæ¯æœ¬ä¹¦+æ¯ä¸ªç”¨æˆ·åªæœ‰ä¸€ä¸ªmetadataè®°å½•ï¼‰
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS book_metadata (
                    book_path TEXT NOT NULL,
                    user_id INTEGER DEFAULT 0,
                    metadata TEXT NOT NULL,
                    last_updated TEXT NOT NULL,
                    PRIMARY KEY (book_path, user_id),
                    FOREIGN KEY (book_path) REFERENCES books (path) ON DELETE CASCADE
                )
            """)
            
            # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_book_metadata_book_user ON book_metadata(book_path, user_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_book_metadata_user ON book_metadata(user_id)")
            
            # åˆ›å»ºä¹¦ç­¾è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS bookmarks (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    book_path TEXT NOT NULL,
                    position TEXT NOT NULL,
                    note TEXT DEFAULT '',
                    timestamp REAL NOT NULL,
                    created_date TEXT NOT NULL,
                    -- æ–°å¢ï¼šé”šç‚¹å­—æ®µï¼ˆè¿ç§»æ—¶é€šè¿‡ PRAGMA+ALTER æ·»åŠ ï¼‰
                    anchor_text TEXT DEFAULT '',
                    anchor_hash TEXT DEFAULT '',
                    -- æ–°å¢ï¼šç”¨æˆ·IDå­—æ®µï¼Œæ”¯æŒå¤šç”¨æˆ·æ¨¡å¼
                    user_id INTEGER DEFAULT 0,
                    FOREIGN KEY (book_path) REFERENCES books (path) ON DELETE CASCADE
                )
            """)
            
            # åˆ›å»ºä¹¦ç­¾ç´¢å¼•
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_bookmarks_book ON bookmarks(book_path)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_bookmarks_timestamp ON bookmarks(timestamp)")
            # è¿ç§»ï¼šæ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„é”šç‚¹åˆ—
            self._add_column_if_not_exists(cursor, "bookmarks", "anchor_text", "TEXT", "''")
            self._add_column_if_not_exists(cursor, "bookmarks", "anchor_hash", "TEXT", "''")
            
            # æ£€æŸ¥å¹¶æ·»åŠ pinyinåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            self._add_column_if_not_exists(cursor, "books", "pinyin", "TEXT")
            
            # æ£€æŸ¥å¹¶æ·»åŠ tagsåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            self._add_column_if_not_exists(cursor, "books", "tags", "TEXT")
            
            # æ£€æŸ¥å¹¶æ·»åŠ file_sizeåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            self._add_column_if_not_exists(cursor, "books", "file_size", "INTEGER DEFAULT 0")
            
            # æ£€æŸ¥å¹¶æ·»åŠ file_sizeåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            self._add_column_if_not_exists(cursor, "books", "file_size", "INTEGER DEFAULT 0")
            
            # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_books_title ON books(title)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_books_pinyin ON books(pinyin)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_books_author ON books(author)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_books_add_date ON books(add_date)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_history_date ON reading_history(read_date)")
            # æ·»åŠ å¤åˆç´¢å¼•ä»¥ä¼˜åŒ–è”åˆæŸ¥è¯¢
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_history_book_user ON reading_history(book_path, user_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_history_book_date ON reading_history(book_path, read_date)")
            # æ·»åŠ æ ¼å¼ç´¢å¼•ç”¨äºç­›é€‰
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_books_format ON books(format)")
            
            # åˆ›å»ºä»£ç†è®¾ç½®è¡¨ï¼ˆæ”¯æŒå¤šæ¡è®°å½•ï¼‰
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS proxy_settings (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL DEFAULT 'é»˜è®¤ä»£ç†',
                    enabled BOOLEAN NOT NULL DEFAULT 0,
                    type TEXT NOT NULL DEFAULT 'HTTP',
                    host TEXT NOT NULL DEFAULT '127.0.0.1',
                    port TEXT NOT NULL DEFAULT '7890',
                    username TEXT DEFAULT '',
                    password TEXT DEFAULT '',
                    created_at TEXT NOT NULL,
                    updated_at TEXT NOT NULL
                )
            """)
            
            # æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„å­—æ®µ
            self._add_column_if_not_exists(cursor, "proxy_settings", "name", "TEXT NOT NULL", "'é»˜è®¤ä»£ç†'")
            self._add_column_if_not_exists(cursor, "proxy_settings", "created_at", "TEXT NOT NULL", "'2024-01-01T00:00:00'")

            # æ’å…¥ä»£ç†æ•°æ®ï¼ˆä½¿ç”¨INSERT OR IGNOREé¿å…é‡å¤ï¼‰
            proxy_settings_data = [
                (1, '7892', 0, 'SOCKS5', '127.0.0.1', '7892', '', '', datetime.now().isoformat(), datetime.now().isoformat()),
                (2, '7890', 1, 'SOCKS5', '127.0.0.1', '7890', '', '', datetime.now().isoformat(), datetime.now().isoformat()),
                (3, '51837', 0, 'SOCKS5', '127.0.0.1', '51837', '', '', datetime.now().isoformat(), datetime.now().isoformat())
            ]
            
            for proxy_data in proxy_settings_data:
                cursor.execute(
                    "INSERT OR IGNORE INTO proxy_settings (id, name, enabled, type, host, port, username, password, created_at, updated_at) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                    proxy_data
                )
            
            # åˆ›å»ºä¹¦ç±ç½‘ç«™è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS novel_sites (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL UNIQUE,
                    url TEXT NOT NULL,
                    storage_folder TEXT NOT NULL,
                    proxy_enabled BOOLEAN NOT NULL DEFAULT 0,
                    selectable_enabled BOOLEAN NOT NULL DEFAULT 1,
                    parser TEXT NOT NULL,
                    tags TEXT DEFAULT '',
                    rating INTEGER NOT NULL DEFAULT 2,  -- æ˜Ÿçº§è¯„åˆ†ï¼Œ0-5ï¼Œé»˜è®¤2æ˜Ÿ
                    created_at TEXT NOT NULL,
                    updated_at TEXT NOT NULL,
                    book_id_example TEXT DEFAULT ''
                )
            """)

            # æ’å…¥ä¹¦ç±ç½‘ç«™è¡¨ï¼ˆä½¿ç”¨INSERT OR IGNOREé¿å…é‡å¤ï¼‰
            novel_sites_data = [
                ('äººå¦»å°è¯´ç½‘', 'https://www.renqixiaoshuo.net', '~/Documents/novels/datas', 1, 1, 'renqixiaoshuo_v2', 'ğŸ”æˆäºº', 0, '2025-10-30T20:57:48.693615', '2025-11-16T14:39:23.344214', '12345' ),
                
            ]
            
            for site_data in novel_sites_data:
                cursor.execute(
                    "INSERT OR IGNORE INTO novel_sites (name, url, storage_folder, proxy_enabled, selectable_enabled, parser, tags, rating, created_at, updated_at, book_id_example) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                    site_data
                )
            
            # åˆ›å»ºçˆ¬å–å†å²è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS crawl_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    site_id INTEGER NOT NULL,
                    novel_id TEXT NOT NULL,
                    novel_title TEXT NOT NULL,
                    crawl_time TEXT NOT NULL,
                    status TEXT NOT NULL,
                    file_path TEXT,
                    error_message TEXT,
                    book_type TEXT DEFAULT 'çŸ­ç¯‡',
                    chapter_count INTEGER DEFAULT 0,
                    last_chapter_index INTEGER DEFAULT -1,
                    last_chapter_title TEXT DEFAULT '',
                    content_hash TEXT DEFAULT '',
                    serial_mode BOOLEAN DEFAULT 0,
                    first_crawl_time TEXT,
                    last_update_time TEXT,
                    FOREIGN KEY (site_id) REFERENCES novel_sites (id) ON DELETE CASCADE
                )
            """)
            
            # åˆ›å»ºç« èŠ‚è¿½è¸ªè¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS chapter_tracking (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    site_id INTEGER NOT NULL,
                    novel_id TEXT NOT NULL,
                    chapter_index INTEGER NOT NULL,
                    chapter_title TEXT NOT NULL,
                    chapter_hash TEXT,
                    crawl_time TEXT NOT NULL,
                    UNIQUE(site_id, novel_id, chapter_index),
                    FOREIGN KEY (site_id) REFERENCES novel_sites (id) ON DELETE CASCADE
                )
            """)
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_novel_sites_name ON novel_sites(name)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_novel_sites_url ON novel_sites(url)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_crawl_history_site_id ON crawl_history(site_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_crawl_history_novel_id ON crawl_history(novel_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_crawl_history_crawl_time ON crawl_history(crawl_time)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_chapter_tracking_site_novel ON chapter_tracking(site_id, novel_id)")
            
             # åˆ›å»ºä¹¦ç±ç½‘ç«™å¤‡æ³¨è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS novel_site_notes (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    site_id INTEGER NOT NULL UNIQUE,
                    note_content TEXT DEFAULT '',
                    created_at TEXT NOT NULL,
                    updated_at TEXT NOT NULL,
                    FOREIGN KEY (site_id) REFERENCES novel_sites (id) ON DELETE CASCADE
                )
            """)
            
            # åˆ›å»ºå¤‡æ³¨è¡¨ç´¢å¼•
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_novel_site_notes_site_id ON novel_site_notes(site_id)")
            
            # æ£€æŸ¥å¹¶æ·»åŠ novel_sitesè¡¨çš„tagsåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            self._add_column_if_not_exists(cursor, "novel_sites", "tags", "TEXT", "''")
            
            # æ£€æŸ¥å¹¶æ·»åŠ novel_sitesè¡¨çš„selectable_enabledåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            self._add_column_if_not_exists(cursor, "novel_sites", "selectable_enabled", "BOOLEAN NOT NULL", "1")
            
            # æ£€æŸ¥å¹¶æ·»åŠ novel_sitesè¡¨çš„book_id_exampleåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            self._add_column_if_not_exists(cursor, "novel_sites", "book_id_example", "TEXT", "''")
            
            # æ£€æŸ¥å¹¶æ·»åŠ novel_sitesè¡¨çš„ratingåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            self._add_column_if_not_exists(cursor, "novel_sites", "rating", "INTEGER NOT NULL", "2")
            
            # æ£€æŸ¥å¹¶æ·»åŠ novel_sitesè¡¨çš„statusåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            self._add_column_if_not_exists(cursor, "novel_sites", "status", "TEXT NOT NULL", "'æ­£å¸¸'")
            
            # æ£€æŸ¥å¹¶æ·»åŠ crawl_historyè¡¨çš„æ–°å­—æ®µï¼ˆæ”¯æŒå¢é‡çˆ¬å–ï¼‰
            self._add_column_if_not_exists(cursor, "crawl_history", "book_type", "TEXT", "'çŸ­ç¯‡'")
            self._add_column_if_not_exists(cursor, "crawl_history", "chapter_count", "INTEGER", "0")
            self._add_column_if_not_exists(cursor, "crawl_history", "last_chapter_index", "INTEGER", "-1")
            self._add_column_if_not_exists(cursor, "crawl_history", "last_chapter_title", "TEXT", "''")
            self._add_column_if_not_exists(cursor, "crawl_history", "content_hash", "TEXT", "''")
            self._add_column_if_not_exists(cursor, "crawl_history", "serial_mode", "BOOLEAN", "0")
            self._add_column_if_not_exists(cursor, "crawl_history", "first_crawl_time", "TEXT")
            self._add_column_if_not_exists(cursor, "crawl_history", "last_update_time", "TEXT")
            self._add_column_if_not_exists(cursor, "crawl_history", "pinyin", "TEXT", "''")

            conn.commit()
    
    def _get_connection_with_retry(self, max_retries: int = 3) -> sqlite3.Connection:
        """
        è·å–æ•°æ®åº“è¿æ¥ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶
        
        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            sqlite3.Connection: æ•°æ®åº“è¿æ¥å¯¹è±¡
            
        Raises:
            sqlite3.OperationalError: è¿æ¥å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        import time
        
        last_error = None
        for attempt in range(max_retries):
            try:
                conn = sqlite3.connect(self.db_path)
                # è®¾ç½®ç¹å¿™è¶…æ—¶
                conn.execute("PRAGMA busy_timeout = 5000")
                return conn
            except sqlite3.OperationalError as e:
                last_error = e
                if "database is locked" in str(e) and attempt < max_retries - 1:
                    wait_time = 0.1 * (2 ** attempt)  # æŒ‡æ•°é€€é¿ï¼š0.1s, 0.2s, 0.4s
                    logger.warning(f"æ•°æ®åº“è¢«é”å®šï¼Œç­‰å¾… {wait_time:.1f}s åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    raise
        
        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªé”™è¯¯
        raise last_error if last_error else sqlite3.OperationalError("æ— æ³•è¿æ¥åˆ°æ•°æ®åº“")
    
    def _build_minimal_metadata(self, book: Book) -> str:
        """
        æ„å»ºç²¾ç®€çš„metadata JSONå­—ç¬¦ä¸²
        
        Args:
            book: ä¹¦ç±å¯¹è±¡
            
        Returns:
            str: metadata JSONå­—ç¬¦ä¸²
        """
        minimal_metadata = {}
        
        # å­˜å‚¨ç« èŠ‚ä¿¡æ¯ï¼ˆåˆ—è¡¨ç»“æ„ï¼Œé€‚åˆå­˜å‚¨åœ¨metadataä¸­ï¼‰
        if book.chapters:
            minimal_metadata['chapters'] = book.chapters
        
        # å­˜å‚¨ä¹¦ç­¾ä¿¡æ¯ï¼ˆåˆ—è¡¨ç»“æ„ï¼Œé€‚åˆå­˜å‚¨åœ¨metadataä¸­ï¼‰
        if book.bookmarks:
            minimal_metadata['bookmarks'] = book.bookmarks
        
        # å­˜å‚¨é”šç‚¹ä¿¡æ¯ï¼ˆç”¨äºè·¨åˆ†é¡µçº åï¼‰
        if book.anchor_text:
            minimal_metadata['anchor_text'] = book.anchor_text
        
        if book.anchor_hash:
            minimal_metadata['anchor_hash'] = book.anchor_hash
        
        # å­˜å‚¨æ–‡ä»¶ä¸å­˜åœ¨æ ‡è®°ï¼ˆå¸ƒå°”å€¼ï¼Œé€‚åˆå­˜å‚¨åœ¨metadataä¸­ï¼‰
        if book.file_not_found:
            minimal_metadata['file_not_found'] = book.file_not_found
        
        # å­˜å‚¨PDFå¯†ç ï¼ˆæ•æ„Ÿä¿¡æ¯ï¼Œé€‚åˆå­˜å‚¨åœ¨metadataä¸­ï¼‰
        if book.password:
            minimal_metadata['password'] = book.password
        
        # æ³¨æ„ï¼šæ–‡ä»¶å¤§å°ç°åœ¨æœ‰ä¸“é—¨çš„file_sizeå­—æ®µå­˜å‚¨ï¼Œä¸å†åœ¨metadataä¸­é‡å¤å­˜å‚¨
        # è¿™æ ·å¯ä»¥é¿å…æ•°æ®å†—ä½™å’Œä¸ä¸€è‡´çš„é—®é¢˜
        
        # ç¡®ä¿metadataä¸ä¸ºç©ºæ—¶è¿›è¡Œåºåˆ—åŒ–
        return json.dumps(minimal_metadata) if minimal_metadata else ""
    
    def add_book(self, book: Book, user_id: Optional[int] = None) -> bool:
        """
        æ·»åŠ ä¹¦ç±åˆ°æ•°æ®åº“
        
        Args:
            book: ä¹¦ç±å¯¹è±¡
            user_id: å¯é€‰ï¼Œç”¨æˆ·IDï¼Œç”¨äºå¤šç”¨æˆ·æ¨¡å¼
            
        Returns:
            bool: æ·»åŠ æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç”Ÿæˆä¹¦åæ‹¼éŸ³
            pinyin_text = convert_to_pinyin(book.title) if book.title else ""
            
            # æ„å»ºç²¾ç®€çš„metadata
            metadata_json = self._build_minimal_metadata(book)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT OR REPLACE INTO books 
                    (path, title, pinyin, author, format, add_date, tags, metadata, file_size)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    book.path,
                    book.title,
                    pinyin_text,
                    book.author,
                    book.format,
                    book.add_date,
                    book.tags if book.tags else "",  # ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²
                    metadata_json,
                    book.file_size
                ))
                
                # å¦‚æœæä¾›äº†ç”¨æˆ·IDï¼Œè®°å½•ç”¨æˆ·å½’å±å…³ç³»
                if user_id is not None:
                    cursor.execute("INSERT OR REPLACE INTO user_books (user_id, book_path) VALUES (?, ?)", (user_id, book.path))
                
                conn.commit()
                
                logger.info(f"ä¹¦ç±å·²æ·»åŠ åˆ°æ•°æ®åº“: {book.title} (metadataå¤§å°: {len(metadata_json)} å­—èŠ‚)")
                return True
        except sqlite3.Error as e:
            logger.error(f"æ·»åŠ ä¹¦ç±åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def get_book(self, book_path: str) -> Optional[Book]:
        """
        ä»æ•°æ®åº“è·å–ä¹¦ç±
        
        Args:
            book_path: ä¹¦ç±è·¯å¾„
            
        Returns:
            Optional[Book]: ä¹¦ç±å¯¹è±¡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM books WHERE path = ?", (book_path,))
                row = cursor.fetchone()
                
                if row:
                    return self._row_to_book(row)
                return None
        except sqlite3.Error as e:
            logger.error(f"ä»æ•°æ®åº“è·å–ä¹¦ç±å¤±è´¥: {e}")
            return None
    
    def get_all_books(self) -> List[Book]:
        """
        è·å–æ‰€æœ‰ä¹¦ç±ï¼ˆä¸åŒºåˆ†ç”¨æˆ·ï¼‰
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM books ORDER BY pinyin ASC")
                rows = cursor.fetchall()
                return [self._row_to_book(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–æ‰€æœ‰ä¹¦ç±å¤±è´¥: {e}")
            return []
    
    def get_books_for_user(self, user_id: int) -> List[Book]:
        """
        è·å–æŸç”¨æˆ·çš„ä¹¦ç±åˆ—è¡¨ï¼ˆæ ¹æ® user_books å½’å±è¡¨ï¼‰
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT b.* FROM books b
                    JOIN user_books ub ON ub.book_path = b.path
                    WHERE ub.user_id = ?
                    ORDER BY b.pinyin ASC
                """, (user_id,))
                rows = cursor.fetchall()
                return [self._row_to_book(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"æŒ‰ç”¨æˆ·è·å–ä¹¦ç±å¤±è´¥: {e}")
            return []

    def get_all_books_with_reading_info(self, user_id: Optional[int] = None) -> List[tuple]:
        """
        æ‰¹é‡è·å–æ‰€æœ‰ä¹¦ç±åŠå…¶é˜…è¯»ä¿¡æ¯ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ï¼‰

        Args:
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™è·å–æ‰€æœ‰ä¹¦ç±

        Returns:
            List[tuple]: ä¹¦ç±å’Œé˜…è¯»ä¿¡æ¯çš„å…ƒç»„åˆ—è¡¨ [(book, reading_info), ...]
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()

                if user_id is None:
                    # éå¤šç”¨æˆ·æ¨¡å¼æˆ–è¶…çº§ç®¡ç†å‘˜ï¼šè·å–æ‰€æœ‰ä¹¦ç±åŠé˜…è¯»ä¿¡æ¯
                    query = """
                        SELECT
                            b.*,
                            bm.metadata as reading_metadata,
                            rh.last_read_date,
                            rh.reading_progress,
                            rh.total_pages,
                            rh.word_count
                        FROM books b
                        LEFT JOIN book_metadata bm ON b.path = bm.book_path AND bm.user_id = 0
                        LEFT JOIN (
                            SELECT
                                book_path,
                                MAX(read_date) as last_read_date,
                                SUM(reading_progress) / COUNT(*) as reading_progress,
                                MAX(total_pages) as total_pages,
                                MAX(word_count) as word_count
                            FROM reading_history
                            GROUP BY book_path
                        ) rh ON b.path = rh.book_path
                        ORDER BY b.pinyin ASC
                    """
                    cursor.execute(query)
                else:
                    # å¤šç”¨æˆ·æ¨¡å¼ï¼šè·å–ç”¨æˆ·ä¹¦ç±åŠé˜…è¯»ä¿¡æ¯
                    query = """
                        SELECT
                            b.*,
                            bm.metadata as reading_metadata,
                            rh.last_read_date,
                            rh.reading_progress,
                            rh.total_pages,
                            rh.word_count
                        FROM books b
                        JOIN user_books ub ON ub.book_path = b.path AND ub.user_id = ?
                        LEFT JOIN book_metadata bm ON b.path = bm.book_path AND bm.user_id = ?
                        LEFT JOIN (
                            SELECT
                                book_path,
                                MAX(read_date) as last_read_date,
                                SUM(reading_progress) / COUNT(*) as reading_progress,
                                MAX(total_pages) as total_pages,
                                MAX(word_count) as word_count
                            FROM reading_history
                            WHERE user_id = ?
                            GROUP BY book_path
                        ) rh ON b.path = rh.book_path
                        ORDER BY b.pinyin ASC
                    """
                    cursor.execute(query, (user_id, user_id, user_id))

                rows = cursor.fetchall()
                results = []

                for row in rows:
                    # å°†è¡Œè½¬æ¢ä¸ºBookå¯¹è±¡
                    book = self._row_to_book(row)

                    # æ„å»ºé˜…è¯»ä¿¡æ¯
                    reading_info = {}

                    # ä¼˜å…ˆä»book_metadataè·å–
                    if row['reading_metadata']:
                        try:
                            metadata = json.loads(row['reading_metadata'])
                            reading_info = {
                                'last_read_date': metadata.get('last_read_date'),
                                'reading_progress': metadata.get('reading_progress', 0),
                                'total_pages': metadata.get('total_pages', 0),
                                'word_count': metadata.get('word_count', 0),
                                'current_page': metadata.get('current_page', 0),
                                'current_position': metadata.get('current_position', 0),
                                'anchor_text': metadata.get('anchor_text', ''),
                                'anchor_hash': metadata.get('anchor_hash', '')
                            }
                        except (json.JSONDecodeError, KeyError):
                            # è§£æå¤±è´¥ï¼Œä½¿ç”¨reading_historyçš„æ•°æ®
                            pass

                    # å¦‚æœbook_metadataæ²¡æœ‰æ•°æ®æˆ–è§£æå¤±è´¥ï¼Œä½¿ç”¨reading_historyçš„æ•°æ®
                    if not reading_info and row['last_read_date']:
                        reading_info = {
                            'last_read_date': row['last_read_date'],
                            'reading_progress': row['reading_progress'] if row['reading_progress'] else 0,
                            'total_pages': row['total_pages'] if row['total_pages'] else 0,
                            'word_count': row['word_count'] if row['word_count'] else 0
                        }

                    results.append((book, reading_info))

                return results

        except sqlite3.Error as e:
            logger.error(f"æ‰¹é‡è·å–ä¹¦ç±å’Œé˜…è¯»ä¿¡æ¯å¤±è´¥: {e}")
            return []
    
    def update_book(self, book: Book, old_path: Optional[str] = None) -> bool:
        """
        æ›´æ–°ä¹¦ç±ä¿¡æ¯
        
        Args:
            book: ä¹¦ç±å¯¹è±¡
            old_path: å¯é€‰çš„åŸä¹¦ç±è·¯å¾„ï¼Œç”¨äºè·¯å¾„æ›´æ–°æ—¶çš„å®šä½
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç”Ÿæˆä¹¦åæ‹¼éŸ³
            pinyin_text = convert_to_pinyin(book.title) if book.title else ""
            
            # æ„å»ºç²¾ç®€çš„metadata
            metadata_json = self._build_minimal_metadata(book)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # å¦‚æœæä¾›äº†æ—§è·¯å¾„ï¼Œä½¿ç”¨æ—§è·¯å¾„ä½œä¸ºWHEREæ¡ä»¶ï¼ˆç”¨äºè·¯å¾„æ›´æ–°ï¼‰
                where_path = old_path if old_path is not None else book.path
                
                cursor.execute("""
                    UPDATE books 
                    SET title = ?, pinyin = ?, author = ?, format = ?, tags = ?, metadata = ?, file_size = ?
                    WHERE path = ?
                """, (
                    book.title,
                    pinyin_text,
                    book.author,
                    book.format,
                    book.tags if book.tags else "",
                    metadata_json,
                    book.file_size,
                    where_path
                ))
                conn.commit()
                
                success = cursor.rowcount > 0
                if success:
                    logger.info(f"ä¹¦ç±ä¿¡æ¯å·²æ›´æ–°: {book.title} (metadataå¤§å°: {len(metadata_json)} å­—èŠ‚)")
                
                return success
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°ä¹¦ç±ä¿¡æ¯å¤±è´¥: {e}")
            return False
    
    def delete_book(self, book_path: str) -> bool:
        """
        åˆ é™¤ä¹¦ç±
        
        Args:
            book_path: ä¹¦ç±è·¯å¾„
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM books WHERE path = ?", (book_path,))
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"åˆ é™¤ä¹¦ç±å¤±è´¥: {e}")
            return False
    
    def search_books(self, keyword: str, format: Optional[str] = None) -> List[Book]:
        """
        æœç´¢ä¹¦ç±ï¼ˆæŒ‰æ ‡é¢˜ã€æ‹¼éŸ³ã€ä½œè€…å’Œæ ‡ç­¾ï¼‰
        
        Args:
            keyword: æœç´¢å…³é”®è¯ï¼ˆæ”¯æŒè‹±æ–‡é€—å·åˆ†å‰²å¤šä¸ªå…³é”®è¯ï¼‰
            format: å¯é€‰ï¼Œæ–‡ä»¶æ ¼å¼ç­›é€‰
            
        Returns:
            List[Book]: åŒ¹é…çš„ä¹¦ç±åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                # æ”¯æŒä½¿ç”¨è‹±æ–‡é€—å·åˆ†å‰²å¤šä¸ªå…³é”®è¯
                keywords = [k.strip() for k in keyword.split(',') if k.strip()]
                
                if not keywords:
                    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå…³é”®è¯ï¼Œè¿”å›ç©ºåˆ—è¡¨
                    return []
                
                # æ„å»ºSQLæŸ¥è¯¢æ¡ä»¶
                conditions = []
                params = []
                
                # ä¸ºæ¯ä¸ªå…³é”®è¯æ„å»ºæœç´¢æ¡ä»¶
                for k in keywords:
                    search_pattern = f"%{k}%"
                    # æ¯ä¸ªå…³é”®è¯åœ¨æ ‡é¢˜ã€æ‹¼éŸ³ã€ä½œè€…ã€æ ‡ç­¾ä¸­æœç´¢
                    condition = "(title LIKE ? OR pinyin LIKE ? OR author LIKE ? OR tags LIKE ?)"
                    conditions.append(condition)
                    params.extend([search_pattern, search_pattern, search_pattern, search_pattern])
                
                # ç»„åˆæ‰€æœ‰æ¡ä»¶ï¼ˆORå…³ç³»ï¼‰
                where_clause = " OR ".join(conditions)
                
                if format:
                    sql = f"""
                        SELECT * FROM books 
                        WHERE ({where_clause}) AND format = ?
                        ORDER BY add_date DESC
                    """
                    params.append(format.lower())
                else:
                    sql = f"""
                        SELECT * FROM books 
                        WHERE {where_clause}
                        ORDER BY add_date DESC
                    """
                
                cursor.execute(sql, params)
                rows = cursor.fetchall()
                
                return [self._row_to_book(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"æœç´¢ä¹¦ç±å¤±è´¥: {e}")
            return []
    
    def get_sorted_books(self, sort_key: str, reverse: bool = False) -> List[Book]:
        """
        è·å–æ’åºåçš„ä¹¦ç±åˆ—è¡¨ï¼ˆä½¿ç”¨æ•°æ®åº“æ’åºï¼‰
        
        Args:
            sort_key: æ’åºé”®ï¼Œå¯é€‰å€¼ä¸º"title", "author", "add_date", "last_read_date", "progress"
            reverse: æ˜¯å¦å€’åº
            
        Returns:
            List[Book]: æ’åºåçš„ä¹¦ç±åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                # æ„å»ºæ’åºSQL
                order_by_clause = self._build_order_by_clause(sort_key, reverse)
                
                cursor.execute(f"SELECT * FROM books {order_by_clause}")
                rows = cursor.fetchall()
                
                return [self._row_to_book(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–æ’åºä¹¦ç±å¤±è´¥: {e}")
            return []
    
    def _build_order_by_clause(self, sort_key: str, reverse: bool) -> str:
        """
        æ„å»ºORDER BYå­å¥
        
        Args:
            sort_key: æ’åºé”®
            reverse: æ˜¯å¦å€’åº
            
        Returns:
            str: ORDER BYå­å¥
        """
        # å­—æ®µæ˜ å°„
        field_mapping = {
            "title": "pinyin",  # æŒ‰ä¹¦åæ’åºæ—¶ä½¿ç”¨æ‹¼éŸ³å­—æ®µ
            "author": "author", 
            "add_date": "add_date",
            "last_read_date": "last_read_date",
            "progress": "reading_progress"
        }
        
        # é»˜è®¤æ’åºå­—æ®µ
        field = field_mapping.get(sort_key, "add_date")
        
        # æ’åºæ–¹å‘
        direction = "DESC" if reverse else "ASC"
        
        # ç‰¹æ®Šå¤„ç†ï¼šå¯¹äºtitleï¼Œå¦‚æœpinyinå­—æ®µä¸ºç©ºï¼Œåˆ™ä½¿ç”¨titleå­—æ®µ
        if sort_key == "title":
            return f"ORDER BY CASE WHEN {field} IS NULL OR {field} = '' THEN title ELSE {field} END {direction}"
        
        # ç‰¹æ®Šå¤„ç†ï¼šå¯¹äºlast_read_dateï¼ŒNULLå€¼æ’åœ¨æœ€å
        if sort_key == "last_read_date":
            return f"ORDER BY CASE WHEN {field} IS NULL THEN 1 ELSE 0 END, {field} {direction}"
        
        # ç‰¹æ®Šå¤„ç†ï¼šå¯¹äºprogressï¼ŒNULLå€¼æ’åœ¨æœ€å
        if sort_key == "progress":
            return f"ORDER BY CASE WHEN {field} IS NULL THEN 1 ELSE 0 END, {field} {direction}"
        
        return f"ORDER BY {field} {direction}"
    
    def add_reading_record(self, book_path: str, duration: int, pages_read: int = 0, 
                          user_id: Optional[int] = None) -> bool:
        """
        æ·»åŠ é˜…è¯»è®°å½•ï¼ˆå·²ä¼˜åŒ–ï¼šä¸å†åŒ…å«metadataå­—æ®µï¼Œmetadataç”±ä¸“é—¨çš„book_metadataè¡¨ç®¡ç†ï¼‰
        
        Args:
            book_path: ä¹¦ç±è·¯å¾„
            duration: é˜…è¯»æ—¶é•¿ï¼ˆç§’ï¼‰
            pages_read: é˜…è¯»é¡µæ•°
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼0
            
        Returns:
            bool: æ·»åŠ æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # è®¾ç½®ç”¨æˆ·IDï¼ˆå¤šç”¨æˆ·æ¨¡å¼å…³é—­æ—¶ä½¿ç”¨0ï¼‰
                user_id_value = user_id if user_id is not None else 0
                
                # è·å–å½“å‰æ—¶é—´
                current_time = datetime.now().isoformat()
                
                # ä»æ–°çš„book_metadataè¡¨è·å–é˜…è¯»è¿›åº¦ç›¸å…³ä¿¡æ¯
                reading_progress = 0
                total_pages = 0
                word_count = 0
                
                # å°è¯•ä»book_metadataè¡¨è·å–æœ€æ–°çš„å…ƒæ•°æ®
                metadata_json = self.get_book_metadata(book_path, user_id_value)
                if metadata_json:
                    try:
                        metadata_dict = json.loads(metadata_json)
                        reading_progress = metadata_dict.get('reading_progress', 0)
                        total_pages = metadata_dict.get('total_pages', 0)
                        word_count = metadata_dict.get('word_count', 0)
                    except (json.JSONDecodeError, KeyError):
                        # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        pass
                
                cursor.execute("""
                    INSERT INTO reading_history (book_path, read_date, duration, pages_read, 
                                                user_id, reading_progress, total_pages, word_count)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    book_path,
                    current_time,
                    duration,
                    pages_read,
                    user_id_value,
                    reading_progress,
                    total_pages,
                    word_count
                ))
                
                # åŒæ—¶æ›´æ–°book_metadataè¡¨ä¸­çš„æœ€åé˜…è¯»æ—¶é—´
                # ä»book_metadataè¡¨è·å–ç°æœ‰çš„å…ƒæ•°æ®
                existing_metadata_json = self.get_book_metadata(book_path, user_id_value)
                existing_metadata = {}
                if existing_metadata_json:
                    try:
                        existing_metadata = json.loads(existing_metadata_json)
                    except json.JSONDecodeError:
                        pass
                
                # æ›´æ–°æœ€åé˜…è¯»æ—¶é—´
                existing_metadata['last_read_date'] = current_time
                
                # ä¿å­˜æ›´æ–°åçš„å…ƒæ•°æ®
                updated_metadata_json = json.dumps(existing_metadata, ensure_ascii=False)
                cursor.execute("""
                    INSERT OR REPLACE INTO book_metadata (book_path, user_id, metadata, last_updated)
                    VALUES (?, ?, ?, ?)
                """, (
                    book_path,
                    user_id_value,
                    updated_metadata_json,
                    current_time
                ))
                
                conn.commit()
                return True
        except sqlite3.Error as e:
            logger.error(f"æ·»åŠ é˜…è¯»è®°å½•å¤±è´¥: {e}")
            return False
    
    def get_reading_history(self, book_path: Optional[str] = None, limit: Optional[int] = None, 
                           user_id: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        è·å–é˜…è¯»å†å²è®°å½•
        
        Args:
            book_path: å¯é€‰ï¼ŒæŒ‡å®šä¹¦ç±è·¯å¾„
            limit: å¯é€‰ï¼Œè¿”å›çš„è®°å½•æ•°é‡é™åˆ¶ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ‰€æœ‰è®°å½•
            user_id: å¯é€‰ï¼Œç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä¸æŒ‰ç”¨æˆ·è¿‡æ»¤
            
        Returns:
            List[Dict[str, Any]]: é˜…è¯»å†å²è®°å½•åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                query = "SELECT * FROM reading_history"
                params = []
                
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                conditions = []
                
                if book_path:
                    conditions.append("book_path = ?")
                    params.append(book_path)
                
                if user_id is not None and user_id > 0:
                    conditions.append("user_id = ?")
                    params.append(user_id)
                
                if conditions:
                    query += " WHERE " + " AND ".join(conditions)
                
                query += " ORDER BY read_date DESC"
                if limit is not None:
                    query += " LIMIT ?"
                    params.append(limit)
                
                cursor.execute(query, params)
                rows = cursor.fetchall()
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–é˜…è¯»å†å²è®°å½•å¤±è´¥: {e}")
            return []

    def get_latest_reading_record(self, book_path: str, user_id: Optional[int] = None) -> Optional[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šä¹¦ç±çš„æœ€æ–°é˜…è¯»è®°å½•
        
        Args:
            book_path: ä¹¦ç±è·¯å¾„
            user_id: å¯é€‰ï¼Œç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä¸æŒ‰ç”¨æˆ·è¿‡æ»¤
            
        Returns:
            Optional[Dict[str, Any]]: æœ€æ–°çš„é˜…è¯»è®°å½•ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                query = "SELECT * FROM reading_history WHERE book_path = ?"
                params = [book_path]
                
                if user_id is not None and user_id > 0:
                    query += " AND user_id = ?"
                    params.append(str(user_id))
                
                query += " ORDER BY read_date DESC LIMIT 1"
                
                cursor.execute(query, params)
                row = cursor.fetchone()
                
                if row:
                    record = dict(row)
                    # å°†read_dateä½œä¸ºlast_read_dateè¿”å›ï¼Œä¿æŒæ¥å£å…¼å®¹æ€§
                    record['last_read_date'] = record.get('read_date')
                    return record
                return None
        except sqlite3.Error as e:
            logger.error(f"è·å–æœ€æ–°é˜…è¯»è®°å½•å¤±è´¥: {e}")
            return None
    
    def _row_to_book(self, row: sqlite3.Row) -> Book:
        """
        å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸ºBookå¯¹è±¡
        
        Args:
            row: æ•°æ®åº“è¡Œ
            
        Returns:
            Book: ä¹¦ç±å¯¹è±¡
        """
        # ä¼˜å…ˆä½¿ç”¨ç‹¬ç«‹å­—æ®µåˆ›å»ºä¹¦ç±å¯¹è±¡
        pinyin_value = row['pinyin'] if 'pinyin' in row else None
        
        # åˆ›å»ºåŸºç¡€ä¹¦ç±å¯¹è±¡
        book = Book(
            path=row['path'],
            title=row['title'],
            author=row['author'],
            tags=row['tags'],
            pinyin=pinyin_value
        )
        
        # è®¾ç½®æ ¼å¼å­—æ®µ
        book.format = row['format']
        
        # è®¾ç½®æ—¥æœŸå­—æ®µ
        book.add_date = row['add_date']
        
        # è®¾ç½®æ–‡ä»¶å¤§å°å­—æ®µ
        if 'file_size' in row:
            book.file_size = row['file_size']
            book.size = book.file_size  # ä¿æŒå…¼å®¹æ€§
        
        # è®¾ç½®æ–‡ä»¶å¤§å°å­—æ®µ
        if 'file_size' in row:
            book.file_size = row['file_size']
            book.size = book.file_size  # ä¿æŒå…¼å®¹æ€§
        
        # æ³¨æ„ï¼šlast_read_dateã€reading_progressã€total_pagesã€word_countå­—æ®µ
        # ç°åœ¨å­˜å‚¨åœ¨reading_historyè¡¨ä¸­ï¼Œä¸åœ¨booksè¡¨ä¸­
        # è¿™äº›å­—æ®µå°†é€šè¿‡å…¶ä»–æ–¹æ³•ä»reading_historyè¡¨è·å–
        
        # è®¾ç½®æ‹¼éŸ³å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'pinyin' in row:
            book.pinyin = row['pinyin'] or ""
        
        # è®¾ç½®æ ‡ç­¾å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'tags' in row:
            book.tags = row['tags'] or ""
        
        # åªæœ‰åœ¨ç‹¬ç«‹å­—æ®µç¼ºå¤±æˆ–éœ€è¦è¡¥å……æ•°æ®æ—¶ï¼Œæ‰ä½¿ç”¨metadataå­—æ®µ
        if row['metadata']:
            try:
                metadata = json.loads(row['metadata'])
                
                # ä»…ä½¿ç”¨metadataå­—æ®µè¡¥å……ç¼ºå¤±çš„æ•°æ®
                # åªæœ‰åœ¨ç‹¬ç«‹å­—æ®µä¸ºç©ºæˆ–æ— æ•ˆæ—¶ï¼Œæ‰ä½¿ç”¨metadataä¸­çš„å¯¹åº”å­—æ®µ
                if not book.title or book.title == "æœªçŸ¥æ ‡é¢˜":
                    book.title = metadata.get('title', book.title)
                
                if not book.author or book.author == "æœªçŸ¥ä½œè€…":
                    book.author = metadata.get('author', book.author)
                
                if not book.pinyin:
                    book.pinyin = metadata.get('pinyin', book.pinyin)
                
                if not book.tags:
                    book.tags = metadata.get('tags', book.tags)
                
                # è¡¥å……å…¶ä»–å¯èƒ½ç¼ºå¤±çš„å­—æ®µï¼ˆé˜…è¯»ç›¸å…³å­—æ®µå·²è¿ç§»åˆ°reading_historyè¡¨ï¼‰
                # reading_progress, total_pages, word_count ç­‰å­—æ®µåº”ä»reading_historyè¡¨è·å–
                
                # è¡¥å……ç« èŠ‚ä¿¡æ¯ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                if not book.chapters and 'chapters' in metadata:
                    book.chapters = metadata.get('chapters', [])
                
                # è¡¥å……ä¹¦ç­¾ä¿¡æ¯ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                if not book.bookmarks and 'bookmarks' in metadata:
                    book.bookmarks = metadata.get('bookmarks', [])
                    
            except (json.JSONDecodeError, KeyError, TypeError) as e:
                logger.warning(f"è§£æmetadataå­—æ®µå¤±è´¥ï¼Œå·²ä½¿ç”¨ç‹¬ç«‹å­—æ®µ: {e}")
        
        return book

    def add_bookmark(self, book_path: str, position: str, note: str = "", anchor_text: Optional[str] = None, anchor_hash: Optional[str] = None, user_id: Optional[int] = None) -> bool:
        """
        æ·»åŠ ä¹¦ç­¾ï¼ˆæ”¯æŒé”šç‚¹ï¼Œå¯é€‰ï¼‰
        
        Args:
            book_path: ä¹¦ç±è·¯å¾„
            position: ä¹¦ç­¾ä½ç½®
            note: ä¹¦ç­¾å¤‡æ³¨
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼0
            
        Returns:
            bool: æ·»åŠ æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                timestamp = time.time()
                created_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                # è®¾ç½®ç”¨æˆ·IDï¼ˆå¤šç”¨æˆ·æ¨¡å¼å…³é—­æ—¶ä½¿ç”¨0ï¼‰
                user_id_value = user_id if user_id is not None else 0
                
                # å…¼å®¹ï¼šå¦‚è¡¨ç»“æ„å·²æœ‰é”šç‚¹åˆ—åˆ™å†™å…¥ï¼Œå¦åˆ™å†™åŸºç¡€åˆ—
                cursor.execute("PRAGMA table_info(bookmarks)")
                bm_columns = [column[1] for column in cursor.fetchall()]
                if 'anchor_text' in bm_columns and 'anchor_hash' in bm_columns:
                    cursor.execute("""
                        INSERT INTO bookmarks (book_path, position, note, timestamp, created_date, anchor_text, anchor_hash, user_id)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (book_path, position, note, timestamp, created_date, anchor_text or "", anchor_hash or "", user_id_value))
                else:
                    cursor.execute("""
                        INSERT INTO bookmarks (book_path, position, note, timestamp, created_date, user_id)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (book_path, position, note, timestamp, created_date, user_id_value))
                
                conn.commit()
                return cursor.lastrowid is not None
        except sqlite3.Error as e:
            logger.error(f"æ·»åŠ ä¹¦ç­¾å¤±è´¥: {e}")
            return False

    def delete_bookmark(self, bookmark_id: int, user_id: Optional[int] = None) -> bool:
        """
        åˆ é™¤ä¹¦ç­¾
        
        Args:
            bookmark_id: ä¹¦ç­¾ID
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä¸æŒ‰ç”¨æˆ·è¿‡æ»¤
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                if user_id is not None and user_id > 0:
                    cursor.execute("DELETE FROM bookmarks WHERE id = ? AND user_id = ?", (bookmark_id, user_id))
                else:
                    cursor.execute("DELETE FROM bookmarks WHERE id = ?", (bookmark_id,))
                
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"åˆ é™¤ä¹¦ç­¾å¤±è´¥: {e}")
            return False

    def get_bookmarks(self, book_path: str, user_id: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šä¹¦ç±çš„æ‰€æœ‰ä¹¦ç­¾
        
        Args:
            book_path: ä¹¦ç±è·¯å¾„
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä¸æŒ‰ç”¨æˆ·è¿‡æ»¤
            
        Returns:
            List[Dict[str, Any]]: ä¹¦ç­¾åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                if user_id is not None and user_id > 0:
                    cursor.execute("""
                        SELECT * FROM bookmarks 
                        WHERE book_path = ? AND user_id = ?
                        ORDER BY timestamp DESC
                    """, (book_path, user_id))
                else:
                    cursor.execute("""
                        SELECT * FROM bookmarks 
                        WHERE book_path = ? 
                        ORDER BY timestamp DESC
                    """, (book_path,))
                
                rows = cursor.fetchall()
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–ä¹¦ç­¾å¤±è´¥: {e}")
            return []

    def get_all_bookmarks(self, user_id: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ä¹¦ç­¾
        
        Args:
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä¸æŒ‰ç”¨æˆ·è¿‡æ»¤
            
        Returns:
            List[Dict[str, Any]]: ä¹¦ç­¾åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                if user_id is not None and user_id > 0:
                    cursor.execute("SELECT * FROM bookmarks WHERE user_id = ? ORDER BY timestamp DESC", (user_id,))
                else:
                    cursor.execute("SELECT * FROM bookmarks ORDER BY timestamp DESC")
                
                rows = cursor.fetchall()
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–æ‰€æœ‰ä¹¦ç­¾å¤±è´¥: {e}")
            return []

    def update_bookmark_note(self, bookmark_id: int, note: str, user_id: Optional[int] = None) -> bool:
        """
        æ›´æ–°ä¹¦ç­¾å¤‡æ³¨
        
        Args:
            bookmark_id: ä¹¦ç­¾ID
            note: æ–°çš„å¤‡æ³¨å†…å®¹
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä¸æŒ‰ç”¨æˆ·è¿‡æ»¤
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                if user_id is not None and user_id > 0:
                    cursor.execute("""
                        UPDATE bookmarks SET note = ? WHERE id = ? AND user_id = ?
                    """, (note, bookmark_id, user_id))
                else:
                    cursor.execute("""
                        UPDATE bookmarks SET note = ? WHERE id = ?
                    """, (note, bookmark_id))
                
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°ä¹¦ç­¾å¤‡æ³¨å¤±è´¥: {e}")
            return False

    # ä»£ç†è®¾ç½®ç›¸å…³æ–¹æ³•ï¼ˆæ”¯æŒå¤šæ¡è®°å½•ï¼‰
    def save_proxy_settings(self, settings: Dict[str, Any]) -> bool:
        """
        ä¿å­˜ä»£ç†è®¾ç½®ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼Œåªä¿å­˜ä¸€æ¡è®°å½•ï¼‰
        
        Args:
            settings: ä»£ç†è®¾ç½®å­—å…¸
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                updated_at = datetime.now().isoformat()
                created_at = datetime.now().isoformat()
                
                # å…ˆåˆ é™¤ç°æœ‰è®¾ç½®ï¼ˆåªä¿ç•™ä¸€æ¡è®°å½•ï¼‰
                cursor.execute("DELETE FROM proxy_settings")
                
                cursor.execute("""
                    INSERT INTO proxy_settings 
                    (name, enabled, type, host, port, username, password, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    settings.get("name", "é»˜è®¤ä»£ç†"),
                    settings.get("enabled", False),
                    settings.get("type", "HTTP"),
                    settings.get("host", "127.0.0.1"),
                    settings.get("port", "7890"),
                    settings.get("username", ""),
                    settings.get("password", ""),
                    created_at,
                    updated_at
                ))
                conn.commit()
                return True
        except sqlite3.Error as e:
            logger.error(f"ä¿å­˜ä»£ç†è®¾ç½®å¤±è´¥: {e}")
            return False

    def get_proxy_settings(self) -> Dict[str, Any]:
        """
        è·å–ä»£ç†è®¾ç½®ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼Œè¿”å›ç¬¬ä¸€æ¡è®°å½•ï¼‰
        
        Returns:
            Dict[str, Any]: ä»£ç†è®¾ç½®å­—å…¸
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM proxy_settings ORDER BY id DESC LIMIT 1")
                row = cursor.fetchone()
                
                if row:
                    return {
                        "id": row["id"],
                        "name": row["name"],
                        "enabled": bool(row["enabled"]),
                        "type": row["type"],
                        "host": row["host"],
                        "port": row["port"],
                        "username": row["username"],
                        "password": row["password"],
                        "created_at": row["created_at"],
                        "updated_at": row["updated_at"]
                    }
                else:
                    # è¿”å›é»˜è®¤è®¾ç½®
                    return {
                        "id": 0,
                        "name": "é»˜è®¤ä»£ç†",
                        "enabled": False,
                        "type": "HTTP",
                        "host": "127.0.0.1",
                        "port": "7890",
                        "username": "",
                        "password": "",
                        "created_at": datetime.now().isoformat(),
                        "updated_at": datetime.now().isoformat()
                    }
        except sqlite3.Error as e:
            logger.error(f"è·å–ä»£ç†è®¾ç½®å¤±è´¥: {e}")
            return {
                "id": 0,
                "name": "é»˜è®¤ä»£ç†",
                "enabled": False,
                "type": "HTTP",
                "host": "127.0.0.1",
                "port": "7890",
                "username": "",
                "password": "",
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat()
            }
    
    def get_all_proxy_settings(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ä»£ç†è®¾ç½®
        
        Returns:
            List[Dict[str, Any]]: ä»£ç†è®¾ç½®åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM proxy_settings ORDER BY name")
                rows = cursor.fetchall()
                
                # ç¡®ä¿æ¯ä¸ªä»£ç†è®¾ç½®éƒ½æœ‰nameå­—æ®µ
                proxy_list = []
                for row in rows:
                    proxy_data = dict(row)
                    # å¦‚æœnameå­—æ®µä¸ºç©ºï¼Œè®¾ç½®é»˜è®¤å€¼
                    if not proxy_data.get('name'):
                        proxy_data['name'] = f"ä»£ç†{proxy_data.get('id', '')}"
                    proxy_list.append(proxy_data)
                
                return proxy_list
        except sqlite3.Error as e:
            logger.error(f"è·å–æ‰€æœ‰ä»£ç†è®¾ç½®å¤±è´¥: {e}")
            return []
    
    def add_proxy_setting(self, proxy_data: Dict[str, Any]) -> bool:
        """
        æ·»åŠ ä»£ç†è®¾ç½®
        
        Args:
            proxy_data: ä»£ç†è®¾ç½®æ•°æ®
            
        Returns:
            bool: æ·»åŠ æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                created_at = datetime.now().isoformat()
                updated_at = datetime.now().isoformat()
                
                cursor.execute("""
                    INSERT INTO proxy_settings 
                    (name, enabled, type, host, port, username, password, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    proxy_data.get("name", "æ–°ä»£ç†"),
                    proxy_data.get("enabled", False),
                    proxy_data.get("type", "HTTP"),
                    proxy_data.get("host", "127.0.0.1"),
                    proxy_data.get("port", "7890"),
                    proxy_data.get("username", ""),
                    proxy_data.get("password", ""),
                    created_at,
                    updated_at
                ))
                conn.commit()
                return True
        except sqlite3.Error as e:
            logger.error(f"æ·»åŠ ä»£ç†è®¾ç½®å¤±è´¥: {e}")
            return False
    
    def update_proxy_setting(self, proxy_id: int, proxy_data: Dict[str, Any]) -> bool:
        """
        æ›´æ–°ä»£ç†è®¾ç½®
        
        Args:
            proxy_id: ä»£ç†ID
            proxy_data: ä»£ç†è®¾ç½®æ•°æ®
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                updated_at = datetime.now().isoformat()
                
                cursor.execute("""
                    UPDATE proxy_settings 
                    SET name = ?, enabled = ?, type = ?, host = ?, port = ?, 
                        username = ?, password = ?, updated_at = ?
                    WHERE id = ?
                """, (
                    proxy_data.get("name", "æ–°ä»£ç†"),
                    proxy_data.get("enabled", False),
                    proxy_data.get("type", "HTTP"),
                    proxy_data.get("host", "127.0.0.1"),
                    proxy_data.get("port", "7890"),
                    proxy_data.get("username", ""),
                    proxy_data.get("password", ""),
                    updated_at,
                    proxy_id
                ))
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°ä»£ç†è®¾ç½®å¤±è´¥: {e}")
            return False
    
    def delete_proxy_setting(self, proxy_id: int) -> bool:
        """
        åˆ é™¤ä»£ç†è®¾ç½®
        
        Args:
            proxy_id: ä»£ç†ID
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM proxy_settings WHERE id = ?", (proxy_id,))
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"åˆ é™¤ä»£ç†è®¾ç½®å¤±è´¥: {e}")
            return False
    
    def enable_proxy_setting(self, proxy_id: int) -> bool:
        """
        å¯ç”¨ä»£ç†è®¾ç½®ï¼ˆåŒæ—¶ç¦ç”¨å…¶ä»–æ‰€æœ‰ä»£ç†ï¼‰
        
        Args:
            proxy_id: ä»£ç†ID
            
        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                updated_at = datetime.now().isoformat()
                
                # ç¦ç”¨æ‰€æœ‰ä»£ç†
                cursor.execute("UPDATE proxy_settings SET enabled = 0, updated_at = ?", (updated_at,))
                
                # å¯ç”¨æŒ‡å®šä»£ç†
                cursor.execute("UPDATE proxy_settings SET enabled = 1, updated_at = ? WHERE id = ?", (updated_at, proxy_id))
                
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"å¯ç”¨ä»£ç†è®¾ç½®å¤±è´¥: {e}")
            return False
    
    def get_enabled_proxy(self) -> Optional[Dict[str, Any]]:
        """
        è·å–å½“å‰å¯ç”¨çš„ä»£ç†è®¾ç½®
        
        Returns:
            Optional[Dict[str, Any]]: å¯ç”¨çš„ä»£ç†è®¾ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM proxy_settings WHERE enabled = 1 LIMIT 1")
                row = cursor.fetchone()
                
                if row:
                    record = dict(row)
                    # å°†read_dateä½œä¸ºlast_read_dateè¿”å›ï¼Œä¿æŒæ¥å£å…¼å®¹æ€§
                    record['last_read_date'] = record.get('read_date')
                    return record
                return None
        except sqlite3.Error as e:
            logger.error(f"è·å–å¯ç”¨çš„ä»£ç†è®¾ç½®å¤±è´¥: {e}")
            return None

    # ä¹¦ç±ç½‘ç«™ç®¡ç†ç›¸å…³æ–¹æ³•
    def save_novel_site(self, site_data: Dict[str, Any]) -> bool:
        """
        ä¿å­˜ä¹¦ç±ç½‘ç«™é…ç½®
        
        Args:
            site_data: ç½‘ç«™é…ç½®å­—å…¸
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                now = datetime.now().isoformat()
                
                if "id" in site_data and site_data["id"]:
                    # æ›´æ–°ç°æœ‰ç½‘ç«™
                    cursor.execute("""
                        UPDATE novel_sites 
                        SET name = ?, url = ?, storage_folder = ?, proxy_enabled = ?, selectable_enabled = ?, parser = ?, tags = ?, rating = ?, book_id_example = ?, status = ?, url_pattern = ?, updated_at = ?
                        WHERE id = ?
                    """, (
                        site_data["name"],
                        site_data["url"],
                        site_data["storage_folder"],
                        site_data["proxy_enabled"],
                        site_data.get("selectable_enabled", True),
                        site_data["parser"],
                        site_data.get("tags", ""),
                        site_data.get("rating", 2),  # é»˜è®¤2æ˜Ÿ
                        site_data.get("book_id_example", ""),
                        site_data.get("status", "æ­£å¸¸"),  # é»˜è®¤çŠ¶æ€ä¸ºæ­£å¸¸
                        site_data.get("url_pattern", ""),  # URLæ¨¡å¼
                        now,
                        site_data["id"]
                    ))
                else:
                    # æ’å…¥æ–°ç½‘ç«™
                    cursor.execute("""
                        INSERT INTO novel_sites 
                        (name, url, storage_folder, proxy_enabled, selectable_enabled, parser, tags, rating, book_id_example, status, url_pattern, created_at, updated_at)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        site_data["name"],
                        site_data["url"],
                        site_data["storage_folder"],
                        site_data["proxy_enabled"],
                        site_data.get("selectable_enabled", True),
                        site_data["parser"],
                        site_data.get("tags", ""),
                        site_data.get("rating", 2),  # é»˜è®¤2æ˜Ÿ
                        site_data.get("book_id_example", ""),
                        site_data.get("status", "æ­£å¸¸"),  # é»˜è®¤çŠ¶æ€ä¸ºæ­£å¸¸
                        site_data.get("url_pattern", ""),  # URLæ¨¡å¼
                        now,
                        now
                    ))
                
                conn.commit()
                return True
        except sqlite3.Error as e:
            logger.error(f"ä¿å­˜ä¹¦ç±ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return False

    def get_novel_sites(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ä¹¦ç±ç½‘ç«™é…ç½®
        
        Returns:
            List[Dict[str, Any]]: ç½‘ç«™é…ç½®åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM novel_sites ORDER BY rating DESC, created_at")
                rows = cursor.fetchall()
                
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–ä¹¦ç±ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return []

    def get_crawled_books_count(self, site_id: int) -> int:
        """
        è·å–æŒ‡å®šç½‘ç«™çˆ¬å–æˆåŠŸçš„ä¹¦ç±æ•°é‡
        
        Args:
            site_id: ç½‘ç«™ID
            
        Returns:
            int: çˆ¬å–æˆåŠŸçš„ä¹¦ç±æ•°é‡
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT COUNT(DISTINCT novel_id) 
                    FROM crawl_history 
                    WHERE site_id = ? AND status = 'success'
                """, (site_id,))
                result = cursor.fetchone()
                return result[0] if result and result[0] is not None else 0
        except sqlite3.Error as e:
            logger.error(f"è·å–ç½‘ç«™çˆ¬å–ä¹¦ç±æ•°é‡å¤±è´¥: {e}")
            return 0

    

    def delete_novel_site(self, site_id: int) -> bool:
        """
        åˆ é™¤ä¹¦ç±ç½‘ç«™é…ç½®
        
        Args:
            site_id: ç½‘ç«™ID
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM novel_sites WHERE id = ?", (site_id,))
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"åˆ é™¤ä¹¦ç±ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return False

    def delete_novel_site_by_id(self, site_id: int) -> bool:
        """
        æ ¹æ®IDåˆ é™¤ä¹¦ç±ç½‘ç«™é…ç½®ï¼ˆåˆ«åæ–¹æ³•ï¼‰
        
        Args:
            site_id: ç½‘ç«™ID
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        return self.delete_novel_site(site_id)

    def update_novel_site_status(self, site_id: int, status: str) -> bool:
        """
        æ›´æ–°ä¹¦ç±ç½‘ç«™çŠ¶æ€
        
        Args:
            site_id: ç½‘ç«™ID
            status: ç½‘ç«™çŠ¶æ€ï¼ˆæ­£å¸¸/å¼‚å¸¸ï¼‰
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                now = datetime.now().isoformat()
                cursor.execute("""
                    UPDATE novel_sites 
                    SET status = ?, updated_at = ?
                    WHERE id = ?
                """, (status, now, site_id))
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°ç½‘ç«™çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def get_cms_t1_sites(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ä½¿ç”¨CMS T1è§£æå™¨çš„ç½‘ç«™
        
        Returns:
            List[Dict[str, Any]]: CMS T1ç½‘ç«™åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM novel_sites 
                    WHERE parser = 'cms_t1_v2' 
                    ORDER BY created_at
                """)
                rows = cursor.fetchall()
                
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–CMS T1ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return []
    
    def create_cms_t1_parsers(self) -> List[Dict[str, Any]]:
        """
        ä¸ºæ‰€æœ‰CMS T1ç½‘ç«™åˆ›å»ºè§£æå™¨å®ä¾‹
        
        Returns:
            List[Dict[str, Any]]: åŒ…å«ç½‘ç«™ä¿¡æ¯å’Œå¯¹åº”è§£æå™¨çš„åˆ—è¡¨
        """
        from src.spiders.base_parser_v2 import BaseParser
        
        # è·å–æ‰€æœ‰CMS T1ç½‘ç«™
        cms_sites = self.get_cms_t1_sites()
        parser_sites = []
        
        for site_data in cms_sites:
            try:
                # åˆ›å»ºä»£ç†é…ç½®
                proxy_config = {
                    'enabled': bool(site_data.get('proxy_enabled', False)),
                    'proxy_url': ''  # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ä»æ•°æ®åº“ä¸­è·å–ä»£ç†URL
                }
                
                # åˆ›å»ºè§£æå™¨å®ä¾‹
                parser = BaseParser.create_cms_t1_parser(site_data, proxy_config)
                
                parser_sites.append({
                    'site_data': site_data,
                    'parser': parser
                })
                
                logger.info(f"å·²ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºCMS T1è§£æå™¨")
                
            except Exception as e:
                logger.error(f"ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºè§£æå™¨å¤±è´¥: {e}")
        
        return parser_sites
    
    def get_cms_t2_sites(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ä½¿ç”¨CMS T2è§£æå™¨çš„ç½‘ç«™
        
        Returns:
            List[Dict[str, Any]]: CMS T2ç½‘ç«™åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM novel_sites 
                    WHERE parser IN ('cms_t2_v2', 'shiyimng_v2', 'lllhhhgroup_v2', 'lxybwcchb_v2', 'jiankangxs_v2') 
                    ORDER BY created_at
                """)
                rows = cursor.fetchall()
                
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–CMS T2ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return []
    
    def create_cms_t2_parsers(self) -> List[Dict[str, Any]]:
        """
        ä¸ºæ‰€æœ‰CMS T2ç½‘ç«™åˆ›å»ºè§£æå™¨å®ä¾‹
        
        Returns:
            List[Dict[str, Any]]: åŒ…å«ç½‘ç«™ä¿¡æ¯å’Œå¯¹åº”è§£æå™¨çš„åˆ—è¡¨
        """
        from src.spiders.base_parser_v2 import BaseParser
        
        # è·å–æ‰€æœ‰CMS T2ç½‘ç«™
        cms_sites = self.get_cms_t2_sites()
        parser_sites = []
        
        for site_data in cms_sites:
            try:
                # åˆ›å»ºä»£ç†é…ç½®
                proxy_config = {
                    'enabled': bool(site_data.get('proxy_enabled', False)),
                    'proxy_url': ''  # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ä»æ•°æ®åº“ä¸­è·å–ä»£ç†URL
                }
                
                # åˆ›å»ºè§£æå™¨å®ä¾‹
                parser = BaseParser.create_cms_t2_parser(site_data, proxy_config)
                
                parser_sites.append({
                    'site_data': site_data,
                    'parser': parser
                })
                
                logger.info(f"å·²ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºCMS T2è§£æå™¨")
                
            except Exception as e:
                logger.error(f"ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºè§£æå™¨å¤±è´¥: {e}")
        
        return parser_sites
    
    def get_cms_t3_sites(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ä½¿ç”¨CMS T3è§£æå™¨çš„ç½‘ç«™
        
        Returns:
            List[Dict[str, Any]]: CMS T3ç½‘ç«™åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM novel_sites 
                    WHERE parser IN ('cms_t3_v2', 'sqranjing_v2', 'auate_v2', 'fqzhufuaini_v2') 
                    ORDER BY created_at
                """)
                rows = cursor.fetchall()
                
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–CMS T3ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return []
    
    def create_cms_t3_parsers(self) -> List[Dict[str, Any]]:
        """
        ä¸ºæ‰€æœ‰CMS T3ç½‘ç«™åˆ›å»ºè§£æå™¨å®ä¾‹
        
        Returns:
            List[Dict[str, Any]]: åŒ…å«ç½‘ç«™ä¿¡æ¯å’Œå¯¹åº”è§£æå™¨çš„åˆ—è¡¨
        """
        from src.spiders.base_parser_v2 import BaseParser
        
        # è·å–æ‰€æœ‰CMS T3ç½‘ç«™
        cms_sites = self.get_cms_t3_sites()
        parser_sites = []
        
        for site_data in cms_sites:
            try:
                # åˆ›å»ºä»£ç†é…ç½®
                proxy_config = {
                    'enabled': bool(site_data.get('proxy_enabled', False)),
                    'proxy_url': ''  # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ä»æ•°æ®åº“ä¸­è·å–ä»£ç†URL
                }
                
                # åˆ›å»ºè§£æå™¨å®ä¾‹
                parser = BaseParser.create_cms_t3_parser(site_data, proxy_config)
                
                parser_sites.append({
                    'site_data': site_data,
                    'parser': parser
                })
                
                logger.info(f"å·²ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºCMS T3è§£æå™¨")
                
            except Exception as e:
                logger.error(f"ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºè§£æå™¨å¤±è´¥: {e}")
        
        return parser_sites
    
    def get_cms_t4_sites(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ä½¿ç”¨CMS T4è§£æå™¨çš„ç½‘ç«™
        
        Returns:
            List[Dict[str, Any]]: CMS T4ç½‘ç«™åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM novel_sites 
                    WHERE parser IN ('cms_t4_v2', 'po18_v2', '87nb_v2') 
                    ORDER BY created_at
                """)
                rows = cursor.fetchall()
                
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–CMS T4ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return []
    
    def create_cms_t4_parsers(self) -> List[Dict[str, Any]]:
        """
        ä¸ºæ‰€æœ‰CMS T4ç½‘ç«™åˆ›å»ºè§£æå™¨å®ä¾‹
        
        Returns:
            List[Dict[str, Any]]: åŒ…å«ç½‘ç«™ä¿¡æ¯å’Œå¯¹åº”è§£æå™¨çš„åˆ—è¡¨
        """
        from src.spiders.base_parser_v2 import BaseParser
        
        # è·å–æ‰€æœ‰CMS T4ç½‘ç«™
        cms_sites = self.get_cms_t4_sites()
        parser_sites = []
        
        for site_data in cms_sites:
            try:
                # åˆ›å»ºä»£ç†é…ç½®
                proxy_config = {
                    'enabled': bool(site_data.get('proxy_enabled', False)),
                    'proxy_url': ''  # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ä»æ•°æ®åº“ä¸­è·å–ä»£ç†URL
                }
                
                # åˆ›å»ºè§£æå™¨å®ä¾‹
                parser = BaseParser.create_cms_t4_parser(site_data, proxy_config)
                
                parser_sites.append({
                    'site_data': site_data,
                    'parser': parser
                })
                
                logger.info(f"å·²ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºCMS T4è§£æå™¨")
                
            except Exception as e:
                logger.error(f"ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºè§£æå™¨å¤±è´¥: {e}")
        
        return parser_sites
    
    def get_cms_t5_sites(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ä½¿ç”¨CMS T5è§£æå™¨çš„ç½‘ç«™
        
        Returns:
            List[Dict[str, Any]]: CMS T5ç½‘ç«™åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM novel_sites 
                    WHERE parser IN ('cms_t5_v2', 'aaanovel_v2', 'xxxnovel_v2', 'hhhbook_v2', 'springnovel_v2', 'thousandnovel_v2', 'dfjstory_v2') 
                    ORDER BY created_at
                """)
                rows = cursor.fetchall()
                
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–CMS T5ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return []
    
    def create_cms_t5_parsers(self) -> List[Dict[str, Any]]:
        """
        ä¸ºæ‰€æœ‰CMS T5ç½‘ç«™åˆ›å»ºè§£æå™¨å®ä¾‹
        
        Returns:
            List[Dict[str, Any]]: åŒ…å«ç½‘ç«™ä¿¡æ¯å’Œå¯¹åº”è§£æå™¨çš„åˆ—è¡¨
        """
        from src.spiders.base_parser_v2 import BaseParser
        
        # è·å–æ‰€æœ‰CMS T5ç½‘ç«™
        cms_sites = self.get_cms_t5_sites()
        parser_sites = []
        
        for site_data in cms_sites:
            try:
                # åˆ›å»ºä»£ç†é…ç½®
                proxy_config = {
                    'enabled': bool(site_data.get('proxy_enabled', False)),
                    'proxy_url': ''  # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ä»æ•°æ®åº“ä¸­è·å–ä»£ç†URL
                }
                
                # åˆ›å»ºè§£æå™¨å®ä¾‹
                parser = BaseParser.create_cms_t5_parser(site_data, proxy_config)
                
                parser_sites.append({
                    'site_data': site_data,
                    'parser': parser
                })
                
                logger.info(f"å·²ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºCMS T5è§£æå™¨")
                
            except Exception as e:
                logger.error(f"ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºè§£æå™¨å¤±è´¥: {e}")
        
        return parser_sites
    
    def get_cms_t6_sites(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ä½¿ç”¨CMS T6è§£æå™¨çš„ç½‘ç«™
        
        Returns:
            List[Dict[str, Any]]: CMS T6ç½‘ç«™åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM novel_sites 
                    WHERE parser = 'cms_t6_v2' 
                    ORDER BY created_at
                """)
                rows = cursor.fetchall()
                
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–CMS T6ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return []
    
    def create_cms_t6_parsers(self) -> List[Dict[str, Any]]:
        """
        ä¸ºæ‰€æœ‰CMS T6ç½‘ç«™åˆ›å»ºè§£æå™¨å®ä¾‹
        
        Returns:
            List[Dict[str, Any]]: åŒ…å«ç½‘ç«™ä¿¡æ¯å’Œå¯¹åº”è§£æå™¨çš„åˆ—è¡¨
        """
        from src.spiders.base_parser_v2 import BaseParser
        
        # è·å–æ‰€æœ‰CMS T6ç½‘ç«™
        cms_sites = self.get_cms_t6_sites()
        parser_sites = []
        
        for site_data in cms_sites:
            try:
                # åˆ›å»ºä»£ç†é…ç½®
                proxy_config = {
                    'enabled': bool(site_data.get('proxy_enabled', False)),
                    'proxy_url': ''  # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ä»æ•°æ®åº“ä¸­è·å–ä»£ç†URL
                }
                
                # åˆ›å»ºè§£æå™¨å®ä¾‹
                parser = BaseParser.create_cms_t6_parser(site_data, proxy_config)
                
                parser_sites.append({
                    'site_data': site_data,
                    'parser': parser
                })
                
                logger.info(f"å·²ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºCMS T6è§£æå™¨")
                
            except Exception as e:
                logger.error(f"ä¸ºç½‘ç«™ {site_data.get('name')} åˆ›å»ºè§£æå™¨å¤±è´¥: {e}")
        
        return parser_sites
    
    def check_site_availability(self, site_url: str, timeout: int = 10) -> Dict[str, Any]:
        """
        æ£€æµ‹ç½‘ç«™æ˜¯å¦å¯ä»¥æ­£å¸¸è®¿é—®
        
        Args:
            site_url: ç½‘ç«™URL
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            Dict[str, Any]: æ£€æµ‹ç»“æœï¼ŒåŒ…å«statusï¼ˆæ­£å¸¸/å¼‚å¸¸ï¼‰ã€response_timeï¼ˆå“åº”æ—¶é—´ï¼‰å’Œmessageï¼ˆè¯¦ç»†ä¿¡æ¯ï¼‰
        """
        result = {
            "status": "å¼‚å¸¸",
            "response_time": 0,
            "message": ""
        }
        
        try:
            # ç¡®ä¿URLæ ¼å¼æ­£ç¡®
            if not site_url.startswith(("http://", "https://")):
                site_url = "https://" + site_url
            
            start_time = time.time()
            response_time = 0
            
            # ä½¿ç”¨HEADè¯·æ±‚å‡å°‘æ•°æ®ä¼ è¾“ï¼Œåªæ£€æŸ¥æ˜¯å¦å¯è¾¾
            try:
                response = requests.head(site_url, timeout=timeout, allow_redirects=True)
                response_time = round((time.time() - start_time) * 1000)  # æ¯«ç§’
                
                # ä¿®æ­£çŠ¶æ€åˆ¤æ–­é€»è¾‘ï¼š403ä¹Ÿè¡¨ç¤ºç½‘ç«™å¯è®¿é—®ï¼Œåªæ˜¯æƒé™é—®é¢˜
                if 200 <= response.status_code < 400 or response.status_code == 403:
                    result["status"] = "æ­£å¸¸"
                    status_desc = "æ­£å¸¸" if response.status_code != 403 else "æ­£å¸¸(éœ€æƒé™)"
                    result["message"] = f"ç½‘ç«™å“åº”{status_desc}ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå“åº”æ—¶é—´: {response_time}ms"
                else:
                    result["message"] = f"ç½‘ç«™å“åº”å¼‚å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå“åº”æ—¶é—´: {response_time}ms"
            except requests.exceptions.RequestException:
                # å¦‚æœHEADè¯·æ±‚å¤±è´¥ï¼Œå°è¯•GETè¯·æ±‚ï¼ˆæœ‰äº›ç½‘ç«™ä¸æ”¯æŒHEADï¼‰
                try:
                    response = requests.get(site_url, timeout=timeout, stream=True, allow_redirects=True)
                    response_time = round((time.time() - start_time) * 1000)  # æ¯«ç§’
                    
                    # ä¿®æ­£çŠ¶æ€åˆ¤æ–­é€»è¾‘ï¼š403ä¹Ÿè¡¨ç¤ºç½‘ç«™å¯è®¿é—®ï¼Œåªæ˜¯æƒé™é—®é¢˜
                    if 200 <= response.status_code < 400 or response.status_code == 403:
                        result["status"] = "æ­£å¸¸"
                        status_desc = "æ­£å¸¸" if response.status_code != 403 else "æ­£å¸¸(éœ€æƒé™)"
                        result["message"] = f"ç½‘ç«™å“åº”{status_desc}ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå“åº”æ—¶é—´: {response_time}ms"
                    else:
                        result["message"] = f"ç½‘ç«™å“åº”å¼‚å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå“åº”æ—¶é—´: {response_time}ms"
                except requests.exceptions.Timeout:
                    result["message"] = f"ç½‘ç«™è®¿é—®è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰"
                except requests.exceptions.ConnectionError:
                    result["message"] = "æ— æ³•è¿æ¥åˆ°ç½‘ç«™ï¼Œå¯èƒ½æ˜¯åŸŸåä¸å­˜åœ¨æˆ–æœåŠ¡å™¨ä¸å¯è¾¾"
                except requests.exceptions.RequestException as e:
                    result["message"] = f"è®¿é—®ç½‘ç«™æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            
            result["response_time"] = response_time
            
        except Exception as e:
            logger.error(f"æ£€æµ‹ç½‘ç«™çŠ¶æ€å¤±è´¥: {e}")
            result["message"] = f"æ£€æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        
        return result
    
    def get_novel_site_by_id(self, site_id: int) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®IDè·å–ä¹¦ç±ç½‘ç«™é…ç½®
        
        Args:
            site_id: ç½‘ç«™ID
            
        Returns:
            Optional[Dict[str, Any]]: ç½‘ç«™é…ç½®å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM novel_sites WHERE id = ?", (site_id,))
                row = cursor.fetchone()
                
                if row:
                    record = dict(row)
                    # å°†read_dateä½œä¸ºlast_read_dateè¿”å›ï¼Œä¿æŒæ¥å£å…¼å®¹æ€§
                    record['last_read_date'] = record.get('read_date')
                    return record
                return None
        except sqlite3.Error as e:
            logger.error(f"æ ¹æ®IDè·å–ä¹¦ç±ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return None

    # çˆ¬å–å†å²è®°å½•ç›¸å…³æ–¹æ³•
    def add_crawl_history(self, site_id: int, novel_id: str, novel_title: str, 
                         status: str, file_path: Optional[str] = None, 
                         error_message: Optional[str] = None,
                         book_type: str = 'çŸ­ç¯‡',
                         chapter_count: int = 0,
                         last_chapter_index: int = -1,
                         last_chapter_title: str = '',
                         content_hash: str = '',
                         serial_mode: bool = False) -> bool:
        """
        æ·»åŠ çˆ¬å–å†å²è®°å½•ï¼ˆæ”¯æŒå¢é‡çˆ¬å–å­—æ®µï¼‰
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
            novel_title: å°è¯´æ ‡é¢˜
            status: çˆ¬å–çŠ¶æ€ï¼ˆsuccess/failedï¼‰
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆæˆåŠŸæ—¶ï¼‰
            error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
            book_type: ä¹¦ç±ç±»å‹ï¼ˆçŸ­ç¯‡/å¤šç« èŠ‚ï¼‰
            chapter_count: ç« èŠ‚æ•°é‡
            last_chapter_index: æœ€åç« èŠ‚ç´¢å¼•
            last_chapter_title: æœ€åç« èŠ‚æ ‡é¢˜
            content_hash: å†…å®¹å“ˆå¸Œ
            serial_mode: æ˜¯å¦è¿è½½æ¨¡å¼
            
        Returns:
            bool: æ·»åŠ æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç”Ÿæˆä¹¦åæ‹¼éŸ³
            pinyin_text = convert_to_pinyin(novel_title) if novel_title else ""
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                crawl_time = datetime.now().isoformat()
                
                cursor.execute("""
                    INSERT INTO crawl_history 
                    (site_id, novel_id, novel_title, crawl_time, status, file_path, error_message,
                     book_type, chapter_count, last_chapter_index, last_chapter_title, 
                     content_hash, serial_mode, first_crawl_time, last_update_time, pinyin)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    site_id,
                    novel_id,
                    novel_title,
                    crawl_time,
                    status,
                    file_path,
                    error_message,
                    book_type,
                    chapter_count,
                    last_chapter_index,
                    last_chapter_title,
                    content_hash,
                    1 if serial_mode else 0,
                    crawl_time if status == 'success' else None,
                    crawl_time if status == 'success' else None,
                    pinyin_text
                ))
                conn.commit()
                return True
        except sqlite3.Error as e:
            logger.error(f"æ·»åŠ çˆ¬å–å†å²è®°å½•å¤±è´¥: {e}")
            return False

    def get_crawl_history_by_site(self, site_id: int, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šç½‘ç«™çš„çˆ¬å–å†å²è®°å½•
        
        Args:
            site_id: ç½‘ç«™ID
            limit: å¯é€‰ï¼Œè¿”å›çš„è®°å½•æ•°é‡é™åˆ¶ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ‰€æœ‰è®°å½•
            
        Returns:
            List[Dict[str, Any]]: çˆ¬å–å†å²è®°å½•åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                query = """
                    SELECT * FROM crawl_history 
                    WHERE site_id = ? 
                    ORDER BY crawl_time DESC
                """
                params = [site_id]
                if limit is not None:
                    query += " LIMIT ?"
                    params.append(limit)
                cursor.execute(query, params)
                rows = cursor.fetchall()
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–çˆ¬å–å†å²è®°å½•å¤±è´¥: {e}")
            return []

    def get_crawl_history_by_novel_id(self, site_id: int, novel_id: str) -> List[Dict[str, Any]]:
        """
        æ ¹æ®å°è¯´IDè·å–çˆ¬å–å†å²è®°å½•
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
            
        Returns:
            List[Dict[str, Any]]: çˆ¬å–å†å²è®°å½•åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM crawl_history 
                    WHERE site_id = ? AND novel_id = ? 
                    ORDER BY crawl_time DESC
                """, (site_id, novel_id))
                rows = cursor.fetchall()
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"æ ¹æ®å°è¯´IDè·å–çˆ¬å–å†å²è®°å½•å¤±è´¥: {e}")
            return []

    def check_novel_exists(self, site_id: int, novel_id: str, check_serial_mode: bool = True) -> bool:
        """
        æ£€æŸ¥å°è¯´æ˜¯å¦å·²ç»ä¸‹è½½è¿‡ä¸”æ–‡ä»¶å­˜åœ¨
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
            check_serial_mode: æ˜¯å¦æ£€æŸ¥è¿è½½æ¨¡å¼ï¼ˆTrueæ—¶è¿è½½ä¹¦ç±è¿”å›Falseå…è®¸æ›´æ–°ï¼‰
            
        Returns:
            bool: å¦‚æœå°è¯´å·²ä¸‹è½½ä¸”æ–‡ä»¶å­˜åœ¨åˆ™è¿”å›True
                  å¦‚æœæ˜¯è¿è½½æ¨¡å¼ä¸”check_serial_mode=Trueï¼Œè¿”å›Falseå…è®¸å¢é‡æ›´æ–°
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT file_path, serial_mode FROM crawl_history 
                    WHERE site_id = ? AND novel_id = ? AND status = 'success'
                    ORDER BY crawl_time DESC 
                    LIMIT 1
                """, (site_id, novel_id))
                row = cursor.fetchone()
                
                if row and row["file_path"]:
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    file_exists = os.path.exists(row["file_path"])
                    
                    # å¦‚æœæ–‡ä»¶å­˜åœ¨ä¸”æ£€æŸ¥è¿è½½æ¨¡å¼
                    if file_exists and check_serial_mode:
                        # å¦‚æœæ˜¯è¿è½½æ¨¡å¼ï¼Œè¿”å›Falseå…è®¸å¢é‡æ›´æ–°
                        serial_mode = bool(row.get("serial_mode", 0))
                        if serial_mode:
                            logger.info(f"å°è¯´ {novel_id} æ˜¯è¿è½½æ¨¡å¼ï¼Œå…è®¸å¢é‡æ›´æ–°")
                            return False
                    
                    return file_exists
                return False
        except sqlite3.Error as e:
            logger.error(f"æ£€æŸ¥å°è¯´æ˜¯å¦å­˜åœ¨å¤±è´¥: {e}")
            return False

    def get_consecutive_failure_count(self, site_id: int, novel_id: str) -> int:
        """
        è·å–å°è¯´çš„è¿ç»­å¤±è´¥æ¬¡æ•°
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
            
        Returns:
            int: è¿ç»­å¤±è´¥æ¬¡æ•°
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT status, error_message FROM crawl_history 
                    WHERE site_id = ? AND novel_id = ? 
                    ORDER BY crawl_time DESC 
                    LIMIT 10
                """, (site_id, novel_id))
                rows = cursor.fetchall()
                
                consecutive_failures = 0
                for row in rows:
                    if row["status"] == "failed":
                        # æ£€æŸ¥æ˜¯å¦æ˜¯è·³è¿‡è®°å½•ï¼Œå¦‚æœæ˜¯åˆ™ä¸è®¡å…¥è¿ç»­å¤±è´¥æ¬¡æ•°
                        if row["error_message"] and "å·²è·³è¿‡" in row["error_message"]:
                            # é‡åˆ°è·³è¿‡è®°å½•å°±åœæ­¢è®¡æ•°ï¼Œé¿å…æ­»å¾ªç¯
                            break
                        consecutive_failures += 1
                    else:
                        # é‡åˆ°æˆåŠŸè®°å½•å°±åœæ­¢è®¡æ•°
                        break
                
                return consecutive_failures
        except sqlite3.Error as e:
            logger.error(f"è·å–è¿ç»­å¤±è´¥æ¬¡æ•°å¤±è´¥: {e}")
            return 0

    def get_saved_chapters(self, site_id: int, novel_id: str, record_id: Optional[int] = None) -> Dict[int, Dict[str, Any]]:
        """
        è·å–å·²ä¿å­˜çš„ç« èŠ‚ä¿¡æ¯
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
            record_id: çˆ¬å–è®°å½•IDï¼ˆå¯é€‰ï¼Œç”¨äºç­›é€‰ç‰¹å®šè®°å½•ï¼‰
        
        Returns:
            {chapter_index: {title, hash, crawl_time}}
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                query = """
                    SELECT chapter_index, chapter_title, chapter_hash, crawl_time
                    FROM chapter_tracking
                    WHERE site_id = ? AND novel_id = ?
                    ORDER BY chapter_index
                """
                cursor.execute(query, (site_id, novel_id))
                rows = cursor.fetchall()
                
                return {
                    row['chapter_index']: {
                        'title': row['chapter_title'],
                        'hash': row['chapter_hash'],
                        'crawl_time': row['crawl_time']
                    }
                    for row in rows
                }
        except sqlite3.Error as e:
            logger.error(f"è·å–å·²ä¿å­˜ç« èŠ‚ä¿¡æ¯å¤±è´¥: {e}")
            return {}

    def batch_add_chapter_tracking(self, site_id: int, novel_id: str, chapters: List[Dict[str, Any]]) -> bool:
        """
        æ‰¹é‡æ·»åŠ ç« èŠ‚è¿½è¸ªè®°å½•
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
            chapters: ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªç« èŠ‚åŒ…å« chapter_index, chapter_title, chapter_hash, crawl_time
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                data = [
                    (site_id, novel_id, ch['chapter_index'], ch['chapter_title'], 
                     ch.get('chapter_hash', ''), ch.get('crawl_time', datetime.now().isoformat()))
                    for ch in chapters
                ]
                
                cursor.executemany("""
                    INSERT OR REPLACE INTO chapter_tracking 
                    (site_id, novel_id, chapter_index, chapter_title, chapter_hash, crawl_time)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, data)
                
                conn.commit()
                logger.info(f"æ‰¹é‡æ·»åŠ  {len(chapters)} ä¸ªç« èŠ‚è¿½è¸ªè®°å½•æˆåŠŸ")
                return True
        except sqlite3.Error as e:
            logger.error(f"æ‰¹é‡æ·»åŠ ç« èŠ‚è¿½è¸ªè®°å½•å¤±è´¥: {e}")
            return False

    def repair_novel_title(self, site_id: int, novel_id: str, new_title: str) -> bool:
        """
        ä¿®å¤å°è¯´æ ‡é¢˜
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
            new_title: æ–°çš„æ ‡é¢˜
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    UPDATE crawl_history
                    SET novel_title = ?
                    WHERE site_id = ? AND novel_id = ?
                """, (new_title, site_id, novel_id))
                
                conn.commit()
                
                if cursor.rowcount > 0:
                    logger.info(f"ä¿®å¤å°è¯´æ ‡é¢˜æˆåŠŸ: {novel_id} -> {new_title}")
                    return True
                else:
                    logger.warning(f"æœªæ‰¾åˆ°éœ€è¦ä¿®å¤çš„è®°å½•: site_id={site_id}, novel_id={novel_id}")
                    return False
                    
        except sqlite3.Error as e:
            logger.error(f"ä¿®å¤å°è¯´æ ‡é¢˜å¤±è´¥: {e}")
            return False
    
    def repair_chapter_tracking(self, site_id: int, novel_id: str) -> Dict[str, Any]:
        """
        ä¿®å¤ç« èŠ‚è¿½è¸ªä¿¡æ¯ï¼šä»å·²æœ‰æ–‡ä»¶ä¸­æå–ç« èŠ‚ä¿¡æ¯å¹¶è¡¥å……åˆ°chapter_trackingè¡¨
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
        
        Returns:
            ä¿®å¤ç»“æœå­—å…¸ {'success': bool, 'count': int, 'message': str}
        """
        try:
            # è·å–æœ€æ–°çš„æˆåŠŸè®°å½•
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT id, file_path, chapter_count, serial_mode
                    FROM crawl_history
                    WHERE site_id = ? AND novel_id = ? AND status = 'success'
                    ORDER BY crawl_time DESC LIMIT 1
                """, (site_id, novel_id))
                
                record = cursor.fetchone()
                
                if not record:
                    return {'success': False, 'count': 0, 'message': 'æœªæ‰¾åˆ°æˆåŠŸè®°å½•'}
                
                record_id = record['id']
                file_path = record['file_path']
                chapter_count = record['chapter_count']
                serial_mode = record['serial_mode']
                
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¿½è¸ªè®°å½•
                cursor.execute("""
                    SELECT COUNT(*) as count
                    FROM chapter_tracking
                    WHERE site_id = ? AND novel_id = ?
                """, (site_id, novel_id))
                
                existing_count = cursor.fetchone()['count']
                
                if existing_count > 0:
                    return {'success': False, 'count': 0, 'message': f'å·²æœ‰{existing_count}æ¡è¿½è¸ªè®°å½•ï¼Œæ— éœ€ä¿®å¤'}
                
                # å¦‚æœä¸æ˜¯è¿è½½æ¨¡å¼æˆ–æ²¡æœ‰ç« èŠ‚ä¿¡æ¯ï¼Œä¸éœ€è¦ä¿®å¤
                if not serial_mode or chapter_count <= 0:
                    return {'success': False, 'count': 0, 'message': 'ä¸æ˜¯è¿è½½æ¨¡å¼ï¼Œæ— éœ€ä¿®å¤'}
                
                # è¯»å–æ–‡ä»¶å¹¶æå–ç« èŠ‚
                if not file_path or not os.path.exists(file_path):
                    return {'success': False, 'count': 0, 'message': 'æ–‡ä»¶ä¸å­˜åœ¨'}
                
                # å°è¯•è§£ææ–‡ä»¶å†…å®¹
                from src.utils.file_helpers import read_text_file, calculate_content_hash
                
                content = read_text_file(file_path)
                
                # ç®€å•çš„ç« èŠ‚æå–é€»è¾‘ï¼šæŸ¥æ‰¾ "###" å¼€å¤´çš„è¡Œä½œä¸ºç« èŠ‚æ ‡é¢˜
                import re
                chapter_pattern = r'^#{3,}\s*(.+?)(?:\s*#{3,})?$'
                chapter_titles = re.findall(chapter_pattern, content, re.MULTILINE)
                
                if not chapter_titles:
                    return {'success': False, 'count': 0, 'message': 'æ— æ³•ä»æ–‡ä»¶ä¸­æå–ç« èŠ‚ä¿¡æ¯'}
                
                # ç”Ÿæˆç« èŠ‚è¿½è¸ªè®°å½•
                chapter_tracking_data = []
                for idx, title in enumerate(chapter_titles):
                    # ä¸ºæ¯ä¸ªç« èŠ‚è®¡ç®—å“ˆå¸Œï¼ˆè¿™é‡Œä½¿ç”¨ç« èŠ‚æ ‡é¢˜çš„å“ˆå¸Œï¼Œå› ä¸ºéš¾ä»¥åˆ†å‰²å…·ä½“å†…å®¹ï¼‰
                    chapter_hash = calculate_content_hash(title)
                    chapter_tracking_data.append({
                        'chapter_index': idx,
                        'chapter_title': title,
                        'chapter_hash': chapter_hash,
                        'crawl_time': datetime.now().isoformat()
                    })
                
                # æ‰¹é‡æ’å…¥
                data = [
                    (site_id, novel_id, ch['chapter_index'], ch['chapter_title'], 
                     ch['chapter_hash'], ch['crawl_time'])
                    for ch in chapter_tracking_data
                ]
                
                cursor.executemany("""
                    INSERT OR REPLACE INTO chapter_tracking 
                    (site_id, novel_id, chapter_index, chapter_title, chapter_hash, crawl_time)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, data)
                
                conn.commit()
                
                logger.info(f"ä¸ºä¹¦ç± {novel_id} ä¿®å¤äº† {len(chapter_tracking_data)} ä¸ªç« èŠ‚è¿½è¸ªè®°å½•")
                
                return {
                    'success': True,
                    'count': len(chapter_tracking_data),
                    'message': f'æˆåŠŸä¿®å¤{len(chapter_tracking_data)}ä¸ªç« èŠ‚è¿½è¸ªè®°å½•'
                }
                
        except sqlite3.Error as e:
            logger.error(f"ä¿®å¤ç« èŠ‚è¿½è¸ªä¿¡æ¯å¤±è´¥: {e}")
            return {'success': False, 'count': 0, 'message': f'æ•°æ®åº“é”™è¯¯: {e}'}
        except Exception as e:
            logger.error(f"ä¿®å¤ç« èŠ‚è¿½è¸ªä¿¡æ¯å¤±è´¥: {e}")
            return {'success': False, 'count': 0, 'message': f'é”™è¯¯: {e}'}
    
    def delete_chapter_tracking(self, site_id: int, novel_id: str) -> bool:
        """
        åˆ é™¤æŒ‡å®šå°è¯´çš„æ‰€æœ‰ç« èŠ‚è¿½è¸ªè®°å½•
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    DELETE FROM chapter_tracking
                    WHERE site_id = ? AND novel_id = ?
                """, (site_id, novel_id))
                conn.commit()
                logger.info(f"åˆ é™¤å°è¯´ {novel_id} çš„ç« èŠ‚è¿½è¸ªè®°å½•æˆåŠŸ")
                return True
        except sqlite3.Error as e:
            logger.error(f"åˆ é™¤ç« èŠ‚è¿½è¸ªè®°å½•å¤±è´¥: {e}")
            return False

    def get_last_successful_crawl(self, site_id: int, novel_id: str) -> Optional[Dict[str, Any]]:
        """
        è·å–æœ€åä¸€æ¬¡æˆåŠŸçš„çˆ¬å–è®°å½•
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
        
        Returns:
            çˆ¬å–è®°å½•å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM crawl_history 
                    WHERE site_id = ? AND novel_id = ? AND status = 'success'
                    ORDER BY crawl_time DESC 
                    LIMIT 1
                """, (site_id, novel_id))
                row = cursor.fetchone()
                return dict(row) if row else None
        except sqlite3.Error as e:
            logger.error(f"è·å–æœ€åä¸€æ¬¡æˆåŠŸçˆ¬å–è®°å½•å¤±è´¥: {e}")
            return None

    def update_crawl_history_full(self, history_id: int, **kwargs) -> bool:
        """
        æ›´æ–°çˆ¬å–å†å²è®°å½•ï¼ˆæ”¯æŒæ‰€æœ‰å­—æ®µï¼‰
        
        Args:
            history_id: è®°å½•ID
            **kwargs: è¦æ›´æ–°çš„å­—æ®µ
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                if not kwargs:
                    return False
                
                update_fields = []
                update_values = []
                
                for key, value in kwargs.items():
                    update_fields.append(f"{key} = ?")
                    update_values.append(value)
                
                update_values.append(history_id)
                
                cursor.execute(f"""
                    UPDATE crawl_history
                    SET {', '.join(update_fields)}
                    WHERE id = ?
                """, update_values)
                
                conn.commit()
                logger.info(f"æ›´æ–°çˆ¬å–å†å²è®°å½• {history_id} æˆåŠŸï¼Œæ›´æ–°å­—æ®µ: {list(kwargs.keys())}")
                return True
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°çˆ¬å–å†å²è®°å½•å¤±è´¥: {e}")
            return False

    def delete_crawl_history(self, history_id: int) -> bool:
        """
        åˆ é™¤çˆ¬å–å†å²è®°å½•
        
        Args:
            history_id: å†å²è®°å½•ID
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM crawl_history WHERE id = ?", (history_id,))
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"åˆ é™¤çˆ¬å–å†å²è®°å½•å¤±è´¥: {e}")
            return False
    
    # ä¹¦ç±ç½‘ç«™å¤‡æ³¨ç›¸å…³æ–¹æ³•
    def save_novel_site_note(self, site_id: int, note_content: str) -> bool:
        """
        ä¿å­˜ä¹¦ç±ç½‘ç«™å¤‡æ³¨
        
        Args:
            site_id: ç½‘ç«™ID
            note_content: å¤‡æ³¨å†…å®¹
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                now = datetime.now().isoformat()
                
                # ä½¿ç”¨INSERT OR REPLACEæ¥ç¡®ä¿æ¯ä¸ªç½‘ç«™åªæœ‰ä¸€ä¸ªå¤‡æ³¨
                cursor.execute("""
                    INSERT OR REPLACE INTO novel_site_notes 
                    (site_id, note_content, created_at, updated_at)
                    VALUES (?, ?, ?, ?)
                """, (
                    site_id,
                    note_content,
                    now,
                    now
                ))
                conn.commit()
                return True
        except sqlite3.Error as e:
            logger.error(f"ä¿å­˜ä¹¦ç±ç½‘ç«™å¤‡æ³¨å¤±è´¥: {e}")
            return False

    def get_novel_site_note(self, site_id: int) -> Optional[str]:
        """
        è·å–ä¹¦ç±ç½‘ç«™å¤‡æ³¨
        
        Args:
            site_id: ç½‘ç«™ID
            
        Returns:
            Optional[str]: å¤‡æ³¨å†…å®¹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT note_content FROM novel_site_notes 
                    WHERE site_id = ?
                """, (site_id,))
                row = cursor.fetchone()
                
                if row:
                    return row[0]
                return None
        except sqlite3.Error as e:
            logger.error(f"è·å–ä¹¦ç±ç½‘ç«™å¤‡æ³¨å¤±è´¥: {e}")
            return None

    def delete_novel_site_note(self, site_id: int) -> bool:
        """
        åˆ é™¤ä¹¦ç±ç½‘ç«™å¤‡æ³¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM novel_site_notes WHERE site_id = ?", (site_id,))
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"åˆ é™¤ä¹¦ç±ç½‘ç«™å¤‡æ³¨å¤±è´¥: {e}")
            return False

    # ===================== ä¼ªç”¨æˆ·ç³»ç»Ÿ API =====================
    def _hash_password(self, password: str) -> str:
        import hashlib
        return hashlib.sha256(("newreader_salt_" + (password or "")).encode("utf-8")).hexdigest()

    def create_user(self, username: str, password: str, role: str = "user") -> Optional[int]:
        """åˆ›å»ºç”¨æˆ·ï¼›è¿”å›ç”¨æˆ·ID"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                now = datetime.now().isoformat()
                cursor.execute("""
                    INSERT INTO users (username, password_hash, role, created_at)
                    VALUES (?, ?, ?, ?)
                """, (username, self._hash_password(password), role, now))
                conn.commit()
                return cursor.lastrowid
        except sqlite3.Error as e:
            logger.error(f"åˆ›å»ºç”¨æˆ·å¤±è´¥: {e}")
            return None

    def set_user_password(self, user_id: int, new_password: str) -> bool:
        """è®¾ç½®ç”¨æˆ·å¯†ç """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("UPDATE users SET password_hash = ? WHERE id = ?", (self._hash_password(new_password), user_id))
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"è®¾ç½®ç”¨æˆ·å¯†ç å¤±è´¥: {e}")
            return False

    def authenticate(self, username: str, password: str) -> Optional[Dict[str, Any]]:
        """è®¤è¯ï¼ŒæˆåŠŸè¿”å›ç”¨æˆ·å­—å…¸"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM users WHERE username = ?", (username,))
                row = cursor.fetchone()
                if not row:
                    return None
                ok = (row["password_hash"] == self._hash_password(password))
                if not ok:
                    return None
                return {"id": row["id"], "username": row["username"], "role": row["role"]}
        except sqlite3.Error as e:
            logger.error(f"è®¤è¯å¤±è´¥: {e}")
            return None

    def get_user_by_id(self, user_id: int) -> Optional[Dict[str, Any]]:
        """æ ¹æ®ç”¨æˆ·IDè·å–ç”¨æˆ·ä¿¡æ¯"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM users WHERE id = ?", (user_id,))
                row = cursor.fetchone()
                if not row:
                    return None
                return {"id": row["id"], "username": row["username"], "role": row["role"]}
        except sqlite3.Error as e:
            logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def set_user_permissions(self, user_id: int, perm_keys: List[str]) -> bool:
        """è®¾ç½®ç”¨æˆ·æƒé™ï¼ˆè¦†ç›–å¼ï¼‰"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM user_permissions WHERE user_id = ?", (user_id,))
                for key in perm_keys:
                    cursor.execute("INSERT OR REPLACE INTO user_permissions (user_id, perm_key, allowed) VALUES (?, ?, 1)", (user_id, key))
                conn.commit()
                return True
        except sqlite3.Error as e:
            logger.error(f"è®¾ç½®ç”¨æˆ·æƒé™å¤±è´¥: {e}")
            return False

    def _has_permission(self, perm_key: str) -> bool:
        """æ£€æŸ¥æƒé™ï¼›è¶…çº§ç®¡ç†æ‹¥æœ‰å…¨éƒ¨æƒé™"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼šæ£€æŸ¥å½“å‰ç”¨æˆ·æ˜¯å¦æœ‰æƒé™
        try:
            from src.utils.multi_user_manager import multi_user_manager
            
            # å¦‚æœå¤šç”¨æˆ·å…³é—­ï¼Œé»˜è®¤æœ‰æ‰€æœ‰æƒé™
            if not multi_user_manager.is_multi_user_enabled():
                return True
                
            current_user = multi_user_manager.get_current_user()
            
            # å¦‚æœå½“å‰ç”¨æˆ·æ˜¯è¶…çº§ç®¡ç†å‘˜ï¼Œæœ‰æ‰€æœ‰æƒé™
            if current_user and current_user.get("role") == "super_admin":
                return True
                
            # æ£€æŸ¥ç”¨æˆ·æƒé™
            user_id = current_user.get("id") if current_user else 0
            role = current_user.get("role") if current_user else None
            return self.has_permission(user_id, perm_key, role)
        except Exception as e:
            logger.error(f"æƒé™æ£€æŸ¥å¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶é»˜è®¤å…è®¸
    
    def has_permission(self, user_id: Optional[int], perm_key: str, role: Optional[str] = None) -> bool:
        """æ£€æŸ¥æƒé™ï¼›è¶…çº§ç®¡ç†æ‹¥æœ‰å…¨éƒ¨æƒé™"""
        try:
            if role == "superadmin" or role == "super_admin":
                return True
            # å¦‚æœuser_idä¸ºNoneæˆ–0ï¼Œè¡¨ç¤ºæœªç™»å½•ç”¨æˆ·ï¼Œé»˜è®¤æ— æƒé™
            if not user_id:
                return False
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT allowed FROM user_permissions WHERE user_id = ? AND perm_key = ?", (user_id, perm_key))
                row = cursor.fetchone()
                return bool(row and (row[0] == 1))
        except sqlite3.Error as e:
            logger.error(f"æ£€æŸ¥æƒé™å¤±è´¥: {e}")
            return False

    def get_all_permissions(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰æƒé™çš„å®Œæ•´ä¿¡æ¯ï¼ˆåŒ…æ‹¬keyå’Œdescriptionï¼‰
        
        Returns:
            List[Dict[str, Any]]: æƒé™åˆ—è¡¨ï¼Œæ¯ä¸ªæƒé™åŒ…å«keyå’Œdescription
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT key, description FROM permissions ORDER BY key")
                rows = cursor.fetchall()
                return [dict(row) for row in rows if row]
        except sqlite3.Error as e:
            logger.error(f"è·å–æ‰€æœ‰æƒé™å¤±è´¥: {e}")
            return []

    def assign_book_to_user(self, user_id: int, book_path: str) -> bool:
        """å°†ä¹¦ç±æ ‡æ³¨ä¸ºè¯¥ç”¨æˆ·çš„ä¹¦ç±ï¼ˆä¸ç”¨äºæ˜¾ç¤ºï¼Œä»…è¿‡æ»¤ç”¨ï¼‰"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("INSERT OR REPLACE INTO user_books (user_id, book_path) VALUES (?, ?)", (user_id, book_path))
                conn.commit()
                return True
        except sqlite3.Error as e:
            logger.error(f"ä¹¦ç±å½’å±ç”¨æˆ·å¤±è´¥: {e}")
            return False

    def get_user_permissions(self, user_id: int) -> List[str]:
        """
        è·å–ç”¨æˆ·çš„æƒé™åˆ—è¡¨
        
        Args:
            user_id: ç”¨æˆ·ID
            
        Returns:
            List[str]: ç”¨æˆ·æ‹¥æœ‰çš„æƒé™é”®åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT perm_key FROM user_permissions 
                    WHERE user_id = ? AND allowed = 1
                """, (user_id,))
                rows = cursor.fetchall()
                return [row[0] for row in rows if row and row[0]]
        except sqlite3.Error as e:
            logger.error(f"è·å–ç”¨æˆ·æƒé™å¤±è´¥: {e}")
            return []

    def update_bookmarks_path(self, old_path: str, new_path: str) -> bool:
        """
        æ›´æ–°ä¹¦ç­¾è¡¨ä¸­çš„ä¹¦ç±è·¯å¾„å¼•ç”¨
        
        Args:
            old_path: åŸä¹¦ç±è·¯å¾„
            new_path: æ–°ä¹¦ç±è·¯å¾„
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("UPDATE bookmarks SET book_path = ? WHERE book_path = ?", (new_path, old_path))
                conn.commit()
                logger.info(f"æ›´æ–°ä¹¦ç­¾è¡¨è·¯å¾„å¼•ç”¨: {old_path} -> {new_path}")
                return True
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°ä¹¦ç­¾è¡¨è·¯å¾„å¼•ç”¨å¤±è´¥: {e}")
            return False

    def update_crawl_history_path(self, old_path: str, new_path: str) -> bool:
        """
        æ›´æ–°çˆ¬å–å†å²è¡¨ä¸­çš„ä¹¦ç±è·¯å¾„å¼•ç”¨å’Œåç§°
        
        Args:
            old_path: åŸä¹¦ç±è·¯å¾„
            new_path: æ–°ä¹¦ç±è·¯å¾„
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                # ä»æ–°è·¯å¾„ä¸­æå–æ–°çš„ä¹¦ç±åç§°ï¼ˆå»æ‰ç›®å½•è·¯å¾„å’Œæ–‡ä»¶æ‰©å±•åï¼‰
                new_title = os.path.splitext(os.path.basename(new_path))[0]
                
                # æ›´æ–°æ–‡ä»¶è·¯å¾„å’Œä¹¦ç±åç§°
                cursor.execute("UPDATE crawl_history SET file_path = ?, novel_title = ? WHERE file_path = ?", 
                             (new_path, new_title, old_path))
                conn.commit()
                logger.info(f"æ›´æ–°çˆ¬å–å†å²è¡¨è·¯å¾„å¼•ç”¨å’Œåç§°: {old_path} -> {new_path}, æ–°åç§°: {new_title}")
                return True
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°çˆ¬å–å†å²è¡¨è·¯å¾„å¼•ç”¨å’Œåç§°å¤±è´¥: {e}")
            return False

    def update_reading_history_path(self, old_path: str, new_path: str) -> bool:
        """
        æ›´æ–°é˜…è¯»å†å²è¡¨ä¸­çš„ä¹¦ç±è·¯å¾„å¼•ç”¨
        
        Args:
            old_path: åŸä¹¦ç±è·¯å¾„
            new_path: æ–°ä¹¦ç±è·¯å¾„
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("UPDATE reading_history SET book_path = ? WHERE book_path = ?", (new_path, old_path))
                conn.commit()
                logger.info(f"æ›´æ–°é˜…è¯»å†å²è¡¨è·¯å¾„å¼•ç”¨: {old_path} -> {new_path}")
                return True
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°é˜…è¯»å†å²è¡¨è·¯å¾„å¼•ç”¨å¤±è´¥: {e}")
            return False

    # ===================== ä¹¦ç±å…ƒæ•°æ®è¡¨ç›¸å…³æ–¹æ³• =====================
    def save_book_metadata(self, book_path: str, metadata: str, user_id: Optional[int] = None) -> bool:
        """
        ä¿å­˜ä¹¦ç±å…ƒæ•°æ®åˆ°æ–°è¡¨
        
        Args:
            book_path: ä¹¦ç±è·¯å¾„
            metadata: å…ƒæ•°æ®JSONå­—ç¬¦ä¸²
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼0
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                last_updated = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                # è®¾ç½®ç”¨æˆ·IDï¼ˆå¤šç”¨æˆ·æ¨¡å¼å…³é—­æ—¶ä½¿ç”¨0ï¼‰
                user_id_value = user_id if user_id is not None else 0
                
                # ä½¿ç”¨INSERT OR REPLACEæ¥ç¡®ä¿æ¯ä¸ªä¹¦ç±+ç”¨æˆ·ç»„åˆåªæœ‰ä¸€ä¸ªè®°å½•
                cursor.execute("""
                    INSERT OR REPLACE INTO book_metadata 
                    (book_path, user_id, metadata, last_updated)
                    VALUES (?, ?, ?, ?)
                """, (book_path, user_id_value, metadata, last_updated))
                
                conn.commit()
                return True
        except sqlite3.Error as e:
            logger.error(f"ä¿å­˜ä¹¦ç±å…ƒæ•°æ®å¤±è´¥: {e}")
            return False

    def get_book_metadata(self, book_path: str, user_id: Optional[int] = None) -> Optional[str]:
        """
        è·å–ä¹¦ç±å…ƒæ•°æ®
        
        Args:
            book_path: ä¹¦ç±è·¯å¾„
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼0
            
        Returns:
            Optional[str]: å…ƒæ•°æ®JSONå­—ç¬¦ä¸²ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # è®¾ç½®ç”¨æˆ·IDï¼ˆå¤šç”¨æˆ·æ¨¡å¼å…³é—­æ—¶ä½¿ç”¨0ï¼‰
                user_id_value = user_id if user_id is not None else 0
                
                cursor.execute("""
                    SELECT metadata FROM book_metadata 
                    WHERE book_path = ? AND user_id = ?
                """, (book_path, user_id_value))
                
                row = cursor.fetchone()
                if row:
                    return row[0]
                return None
        except sqlite3.Error as e:
            logger.error(f"è·å–ä¹¦ç±å…ƒæ•°æ®å¤±è´¥: {e}")
            return None

    def delete_book_metadata(self, book_path: str, user_id: Optional[int] = None) -> bool:
        """
        åˆ é™¤ä¹¦ç±å…ƒæ•°æ®
        
        Args:
            book_path: ä¹¦ç±è·¯å¾„
            user_id: ç”¨æˆ·IDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼0
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # è®¾ç½®ç”¨æˆ·IDï¼ˆå¤šç”¨æˆ·æ¨¡å¼å…³é—­æ—¶ä½¿ç”¨0ï¼‰
                user_id_value = user_id if user_id is not None else 0
                
                cursor.execute("""
                    DELETE FROM book_metadata 
                    WHERE book_path = ? AND user_id = ?
                """, (book_path, user_id_value))
                
                conn.commit()
                return cursor.rowcount > 0
        except sqlite3.Error as e:
            logger.error(f"åˆ é™¤ä¹¦ç±å…ƒæ•°æ®å¤±è´¥: {e}")
            return False

    def update_book_metadata_path(self, old_path: str, new_path: str) -> bool:
        """
        æ›´æ–°ä¹¦ç±å…ƒæ•°æ®è¡¨ä¸­çš„ä¹¦ç±è·¯å¾„å¼•ç”¨
        
        Args:
            old_path: åŸä¹¦ç±è·¯å¾„
            new_path: æ–°ä¹¦ç±è·¯å¾„
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("UPDATE book_metadata SET book_path = ? WHERE book_path = ?", (new_path, old_path))
                conn.commit()
                logger.info(f"æ›´æ–°ä¹¦ç±å…ƒæ•°æ®è¡¨è·¯å¾„å¼•ç”¨: {old_path} -> {new_path}")
                return True
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°ä¹¦ç±å…ƒæ•°æ®è¡¨è·¯å¾„å¼•ç”¨å¤±è´¥: {e}")
            return False

    def migrate_reading_history_metadata(self) -> bool:
        """
        å°†ç°æœ‰reading_historyè¡¨ä¸­çš„metadataè¿ç§»åˆ°æ–°çš„book_metadataè¡¨
        
        Returns:
            bool: è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # è·å–æ‰€æœ‰æœ‰metadataçš„é˜…è¯»è®°å½•
                cursor.execute("""
                    SELECT DISTINCT book_path, user_id, metadata 
                    FROM reading_history 
                    WHERE metadata IS NOT NULL AND metadata != ''
                """)
                
                rows = cursor.fetchall()
                migrated_count = 0
                
                for row in rows:
                    book_path, user_id, metadata = row
                    
                    # è¿ç§»åˆ°æ–°è¡¨
                    last_updated = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    cursor.execute("""
                        INSERT OR REPLACE INTO book_metadata 
                        (book_path, user_id, metadata, last_updated)
                        VALUES (?, ?, ?, ?)
                    """, (book_path, user_id or 0, metadata, last_updated))
                    
                    migrated_count += 1
                
                conn.commit()
                logger.info(f"æˆåŠŸè¿ç§» {migrated_count} æ¡metadataè®°å½•åˆ°æ–°è¡¨")
                return True
        except sqlite3.Error as e:
            logger.error(f"è¿ç§»metadataå¤±è´¥: {e}")
            return False

    def update_user_books_path(self, old_path: str, new_path: str) -> bool:
        """
        æ›´æ–°ç”¨æˆ·ä¹¦ç±å…³è”è¡¨ä¸­çš„ä¹¦ç±è·¯å¾„å¼•ç”¨
        
        Args:
            old_path: åŸä¹¦ç±è·¯å¾„
            new_path: æ–°ä¹¦ç±è·¯å¾„
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("UPDATE user_books SET book_path = ? WHERE book_path = ?", (new_path, old_path))
                conn.commit()
                logger.info(f"æ›´æ–°ç”¨æˆ·ä¹¦ç±å…³è”è¡¨è·¯å¾„å¼•ç”¨: {old_path} -> {new_path}")
                return True
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°ç”¨æˆ·ä¹¦ç±å…³è”è¡¨è·¯å¾„å¼•ç”¨å¤±è´¥: {e}")
            return False

    def update_vocabulary_path(self, old_path: str, new_path: str) -> bool:
        """
        æ›´æ–°è¯æ±‡è¡¨ä¸­çš„ä¹¦ç±è·¯å¾„å¼•ç”¨
        
        Args:
            old_path: åŸä¹¦ç±è·¯å¾„
            new_path: æ–°ä¹¦ç±è·¯å¾„
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("UPDATE vocabulary SET book_id = ? WHERE book_id = ?", (new_path, old_path))
                conn.commit()
                logger.info(f"æ›´æ–°è¯æ±‡è¡¨è·¯å¾„å¼•ç”¨: {old_path} -> {new_path}")
                return True
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°è¯æ±‡è¡¨è·¯å¾„å¼•ç”¨å¤±è´¥: {e}")
            return False

    def update_crawl_history_status(self, site_id: int, novel_id: str, status: str, 
                                   file_path: Optional[str] = None, 
                                   novel_title: Optional[str] = None,
                                   error_message: Optional[str] = None) -> bool:
        """
        æ›´æ–°çˆ¬å–å†å²è®°å½•çš„çŠ¶æ€å’Œæ–‡ä»¶è·¯å¾„
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
            status: çŠ¶æ€ï¼ˆsuccess/failedï¼‰
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            novel_title: å°è¯´æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æ„å»ºæ›´æ–°è¯­å¥
                update_fields = ["status = ?"]
                update_values = [status]
                
                if file_path:
                    update_fields.append("file_path = ?")
                    update_values.append(file_path)
                
                if novel_title:
                    update_fields.append("novel_title = ?")
                    update_values.append(novel_title)
                
                if error_message is not None:
                    update_fields.append("error_message = ?")
                    update_values.append(error_message)
                
                # æ·»åŠ æ›´æ–°æ—¶é—´
                update_fields.append("crawl_time = ?")
                update_values.append(datetime.now().isoformat())
                
                update_values.extend([site_id, novel_id])
                
                update_sql = f"""
                    UPDATE crawl_history 
                    SET {', '.join(update_fields)}
                    WHERE site_id = ? AND novel_id = ? AND id = (
                        SELECT id FROM crawl_history 
                        WHERE site_id = ? AND novel_id = ? 
                        ORDER BY crawl_time DESC 
                        LIMIT 1
                    )
                """
                
                # éœ€è¦é‡å¤å‚æ•°ï¼Œå› ä¸ºå­æŸ¥è¯¢ä¸­ä¹Ÿéœ€è¦
                update_values.extend([site_id, novel_id])
                cursor.execute(update_sql, update_values)
                rows_affected = cursor.rowcount
                conn.commit()
                
                logger.info(f"æ›´æ–°çˆ¬å–å†å²è®°å½•çŠ¶æ€: ç½‘ç«™ID={site_id}, å°è¯´ID={novel_id}, çŠ¶æ€={status}, å½±å“è¡Œæ•°={rows_affected}")
                if rows_affected == 0:
                    logger.warning(f"æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®°å½•è¿›è¡Œæ›´æ–°: site_id={site_id}, novel_id={novel_id}")
                return True
                
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°çˆ¬å–å†å²è®°å½•çŠ¶æ€å¤±è´¥: {e}")
            return False

    def update_crawl_history_error(self, site_id: int, novel_id: str, error_message: str) -> bool:
        """
        æ›´æ–°çˆ¬å–å†å²è®°å½•çš„é”™è¯¯ä¿¡æ¯
        
        Args:
            site_id: ç½‘ç«™ID
            novel_id: å°è¯´ID
            error_message: é”™è¯¯ä¿¡æ¯
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    UPDATE crawl_history 
                    SET error_message = ?, status = 'failed', crawl_time = ?
                    WHERE site_id = ? AND novel_id = ?
                """, (error_message, datetime.now().isoformat(), site_id, novel_id))
                
                conn.commit()
                logger.info(f"æ›´æ–°çˆ¬å–å†å²è®°å½•é”™è¯¯ä¿¡æ¯: ç½‘ç«™ID={site_id}, å°è¯´ID={novel_id}")
                return True
                
        except sqlite3.Error as e:
            logger.error(f"æ›´æ–°çˆ¬å–å†å²è®°å½•é”™è¯¯ä¿¡æ¯å¤±è´¥: {e}")
            return False